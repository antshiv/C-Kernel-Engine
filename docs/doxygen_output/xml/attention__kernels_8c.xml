<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.1" xml:lang="en-US">
  <compounddef id="attention__kernels_8c" kind="file" language="C++">
    <compoundname>attention_kernels.c</compoundname>
    <includes refid="bf16__utils_8h" local="yes">bf16_utils.h</includes>
    <includes refid="ckernel__engine_8h" local="yes">ckernel_engine.h</includes>
    <includes local="no">math.h</includes>
    <includes local="no">stdlib.h</includes>
    <incdepgraph>
      <node id="3">
        <label>stdint.h</label>
      </node>
      <node id="8">
        <label>stdlib.h</label>
      </node>
      <node id="2">
        <label>bf16_utils.h</label>
        <link refid="bf16__utils_8h"/>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
      </node>
      <node id="1">
        <label>attention_kernels.c</label>
        <link refid="attention__kernels_8c"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
        <childnode refid="7" relation="include">
        </childnode>
        <childnode refid="8" relation="include">
        </childnode>
      </node>
      <node id="5">
        <label>ckernel_engine.h</label>
        <link refid="ckernel__engine_8h"/>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="6" relation="include">
        </childnode>
      </node>
      <node id="4">
        <label>stddef.h</label>
      </node>
      <node id="7">
        <label>math.h</label>
      </node>
      <node id="6">
        <label>cpu_features.h</label>
        <link refid="cpu__features_8h"/>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
      </node>
    </incdepgraph>
      <sectiondef kind="define">
      <memberdef kind="define" id="attention__kernels_8c_1a686599872afcb86c5fc7ad5e5e5b4773" prot="public" static="no">
        <name>FLASH_QUERY_IMPL</name>
        <initializer><ref refid="attention__kernels_8c_1aa09ace92ab625ae8365e61f47c3d93a5" kindref="member">attention_flash_query_causal</ref></initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="777" column="14"/>
      </memberdef>
      <memberdef kind="define" id="attention__kernels_8c_1aba8a26d95a9c96411b5fea006f2097e4" prot="public" static="no">
        <name>FLASH_QUERY_IMPL_DECODE</name>
        <initializer><ref refid="attention__kernels_8c_1aa09ace92ab625ae8365e61f47c3d93a5" kindref="member">attention_flash_query_causal</ref></initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="830" column="14"/>
      </memberdef>
      </sectiondef>
      <sectiondef kind="func">
      <memberdef kind="function" id="attention__kernels_8c_1ad611fd5e8dba3e906482d6e68f919788" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_backward_causal_head_major</definition>
        <argsstring>(const float *d_output, const float *q, const float *k, const float *v, const float *attn_weights, float *d_q, float *d_k, float *d_v, float *d_scores, int num_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_backward_causal_head_major</name>
        <param>
          <type>const float *</type>
          <declname>d_output</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>attn_weights</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_q</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_k</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_scores</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="1071" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="1071" bodyend="1092"/>
        <references refid="attention__kernels_8c_1adbd2b55fbc53b6e288c98813b61cd6e3" compoundref="attention__kernels_8c" startline="942" endline="1068">attention_backward_causal_head_major_gqa</references>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1adbd2b55fbc53b6e288c98813b61cd6e3" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_backward_causal_head_major_gqa</definition>
        <argsstring>(const float *d_output, const float *q, const float *k, const float *v, const float *attn_weights, float *d_q, float *d_k, float *d_v, float *d_scores, int num_heads, int num_kv_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_backward_causal_head_major_gqa</name>
        <param>
          <type>const float *</type>
          <declname>d_output</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>attn_weights</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_q</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_k</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_scores</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_kv_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="942" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="942" bodyend="1068"/>
        <references refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" compoundref="attention__kernels_8c" startline="23" endline="31">qkv_index</references>
        <references refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" compoundref="attention__kernels_8c" startline="35" endline="43">score_index</references>
        <referencedby refid="ckernel__engine_8h_1ad611fd5e8dba3e906482d6e68f919788" compoundref="attention__kernels_8c" startline="1071" endline="1092">attention_backward_causal_head_major</referencedby>
        <referencedby refid="ckernel__engine_8h_1a1a95c2e93bfbe603df487d0c0eb5ea2b" compoundref="attention__kernels_8c" startline="884" endline="940">attention_backward_causal_head_major_gqa_bf16</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1a1b75acba52e39a2063646dc1dff62ef4" compoundref="ckernel__orchestration_8c" startline="2154" endline="2294">ck_layer_backward_rmsnorm_swiglu</referencedby>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a1a95c2e93bfbe603df487d0c0eb5ea2b" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_backward_causal_head_major_gqa_bf16</definition>
        <argsstring>(const uint16_t *d_output, float *d_x, const uint16_t *q, const uint16_t *k, const uint16_t *v, const float *attn_weights, float *d_q, float *d_k, float *d_v, float *d_scores, int num_heads, int num_kv_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_backward_causal_head_major_gqa_bf16</name>
        <param>
          <type>const uint16_t *</type>
          <declname>d_output</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_x</declname>
        </param>
        <param>
          <type>const uint16_t *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const uint16_t *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const uint16_t *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>attn_weights</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_q</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_k</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>d_scores</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_kv_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="884" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="884" bodyend="940"/>
        <references refid="attention__kernels_8c_1adbd2b55fbc53b6e288c98813b61cd6e3" compoundref="attention__kernels_8c" startline="942" endline="1068">attention_backward_causal_head_major_gqa</references>
        <references refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" compoundref="attention__kernels_8c" startline="10" endline="19">convert_bf16_tensor</references>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1aa09ace92ab625ae8365e61f47c3d93a5" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>static void attention_flash_query_causal</definition>
        <argsstring>(const float *q_vec, const float *k_head, const float *v_head, int kv_tokens, int head_dim, int aligned_head_dim, float scale, float *out_vec)</argsstring>
        <name>attention_flash_query_causal</name>
        <param>
          <type>const float *</type>
          <declname>q_vec</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k_head</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v_head</declname>
        </param>
        <param>
          <type>int</type>
          <declname>kv_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>float</type>
          <declname>scale</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>out_vec</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="691" column="13" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="691" bodyend="747"/>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a3d8664b9e0808546484af9ec7d4ddfe1" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_forward_causal_head_major</definition>
        <argsstring>(const float *q, const float *k, const float *v, float *scores, float *output, int num_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_forward_causal_head_major</name>
        <param>
          <type>const float *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>scores</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>output</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="59" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="59" bodyend="123"/>
        <references refid="ckernel__engine_8h_1a920868f80137fe3e0c9cd11acb7ba567" compoundref="softmax__kernels_8c" startline="116" endline="297">causal_softmax_head_major</references>
        <references refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" compoundref="attention__kernels_8c" startline="23" endline="31">qkv_index</references>
        <references refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" compoundref="attention__kernels_8c" startline="35" endline="43">score_index</references>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a57b7a6f6f08b030fd8d5fbf87fa31ac7" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_forward_causal_head_major_exact</definition>
        <argsstring>(const float *q, const float *k, const float *v, float *scores, float *output, int num_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_forward_causal_head_major_exact</name>
        <param>
          <type>const float *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>scores</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>output</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="127" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="127" bodyend="191"/>
        <references refid="ckernel__engine_8h_1a6ea7267298ef550524a6277b817a8ffb" compoundref="softmax__kernels_8c" startline="302" endline="340">causal_softmax_head_major_exact</references>
        <references refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" compoundref="attention__kernels_8c" startline="23" endline="31">qkv_index</references>
        <references refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" compoundref="attention__kernels_8c" startline="35" endline="43">score_index</references>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a3e1aa7c55e515fd996318da27c2c5ade" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_forward_causal_head_major_gqa</definition>
        <argsstring>(const float *q, const float *k, const float *v, float *scores, float *output, int num_heads, int num_kv_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_forward_causal_head_major_gqa</name>
        <param>
          <type>const float *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>scores</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>output</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_kv_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="195" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="195" bodyend="253"/>
        <references refid="ckernel__engine_8h_1a920868f80137fe3e0c9cd11acb7ba567" compoundref="softmax__kernels_8c" startline="116" endline="297">causal_softmax_head_major</references>
        <references refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" compoundref="attention__kernels_8c" startline="23" endline="31">qkv_index</references>
        <references refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" compoundref="attention__kernels_8c" startline="35" endline="43">score_index</references>
        <referencedby refid="ckernel__orchestration_8h_1ab7dfa86e5bb0d80f0e346f85e870cb1d" compoundref="ckernel__orchestration_8c" startline="749" endline="854">ck_layer_forward_rmsnorm_swiglu</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1a7b9d9ef1181d1fa0f7c8b19eefb7846d" compoundref="ckernel__orchestration_8c" startline="1494" endline="1599">ck_layer_forward_rmsnorm_swiglu_q4_k</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1a4bfddd851b4b52f7502330118a3e853d" compoundref="ckernel__orchestration_8c" startline="1872" endline="1980">ck_layer_forward_rmsnorm_swiglu_quant</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1acc9d893cdd6cf7bf0dbf35d42c5f0e99" compoundref="ckernel__orchestration_8c" startline="856" endline="961">ck_layer_forward_rmsnorm_swiglu_ref</referencedby>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1af749b0ec6a9cc8a63033fa2069759722" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_forward_causal_head_major_gqa_bf16</definition>
        <argsstring>(const uint16_t *q, const uint16_t *k, const uint16_t *v, float *scores, float *output, int num_heads, int num_kv_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_forward_causal_head_major_gqa_bf16</name>
        <param>
          <type>const uint16_t *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const uint16_t *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const uint16_t *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>scores</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>output</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_kv_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="319" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="319" bodyend="359"/>
        <references refid="attention__kernels_8c_1a04febaa686747fdfad9e915b627a0915" compoundref="attention__kernels_8c" startline="258" endline="317">attention_forward_causal_head_major_gqa_exact</references>
        <references refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" compoundref="attention__kernels_8c" startline="10" endline="19">convert_bf16_tensor</references>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a04febaa686747fdfad9e915b627a0915" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_forward_causal_head_major_gqa_exact</definition>
        <argsstring>(const float *q, const float *k, const float *v, float *scores, float *output, int num_heads, int num_kv_heads, int num_tokens, int head_dim, int aligned_head_dim, int aligned_context_window)</argsstring>
        <name>attention_forward_causal_head_major_gqa_exact</name>
        <param>
          <type>const float *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>scores</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>output</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_kv_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="258" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="258" bodyend="317"/>
        <references refid="ckernel__engine_8h_1a6ea7267298ef550524a6277b817a8ffb" compoundref="softmax__kernels_8c" startline="302" endline="340">causal_softmax_head_major_exact</references>
        <references refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" compoundref="attention__kernels_8c" startline="23" endline="31">qkv_index</references>
        <references refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" compoundref="attention__kernels_8c" startline="35" endline="43">score_index</references>
        <referencedby refid="ckernel__engine_8h_1af749b0ec6a9cc8a63033fa2069759722" compoundref="attention__kernels_8c" startline="319" endline="359">attention_forward_causal_head_major_gqa_bf16</referencedby>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1aac305a28084fe73b2264ae57613ba3ea" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_forward_causal_head_major_gqa_flash</definition>
        <argsstring>(const float *q, const float *k, const float *v, float *output, int num_heads, int num_kv_heads, int num_tokens, int head_dim, int aligned_head_dim)</argsstring>
        <name>attention_forward_causal_head_major_gqa_flash</name>
        <param>
          <type>const float *</type>
          <declname>q</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>output</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_kv_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="749" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="749" bodyend="796"/>
        <references refid="attention__kernels_8c_1a686599872afcb86c5fc7ad5e5e5b4773">FLASH_QUERY_IMPL</references>
        <references refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" compoundref="attention__kernels_8c" startline="23" endline="31">qkv_index</references>
        <referencedby refid="ckernel__orchestration_8h_1ab7dfa86e5bb0d80f0e346f85e870cb1d" compoundref="ckernel__orchestration_8c" startline="749" endline="854">ck_layer_forward_rmsnorm_swiglu</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1a7b9d9ef1181d1fa0f7c8b19eefb7846d" compoundref="ckernel__orchestration_8c" startline="1494" endline="1599">ck_layer_forward_rmsnorm_swiglu_q4_k</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1a4bfddd851b4b52f7502330118a3e853d" compoundref="ckernel__orchestration_8c" startline="1872" endline="1980">ck_layer_forward_rmsnorm_swiglu_quant</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1acc9d893cdd6cf7bf0dbf35d42c5f0e99" compoundref="ckernel__orchestration_8c" startline="856" endline="961">ck_layer_forward_rmsnorm_swiglu_ref</referencedby>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a84803f8c5509c325dd6b9feec50a0493" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void attention_forward_decode_head_major_gqa_flash</definition>
        <argsstring>(const float *q_token, const float *k_cache, const float *v_cache, float *out_token, int num_heads, int num_kv_heads, int kv_tokens, int cache_capacity, int head_dim, int aligned_head_dim)</argsstring>
        <name>attention_forward_decode_head_major_gqa_flash</name>
        <param>
          <type>const float *</type>
          <declname>q_token</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>k_cache</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>v_cache</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>out_token</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_kv_heads</declname>
        </param>
        <param>
          <type>int</type>
          <declname>kv_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>cache_capacity</declname>
        </param>
        <param>
          <type>int</type>
          <declname>head_dim</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="798" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="798" bodyend="847"/>
        <references refid="attention__kernels_8c_1aba8a26d95a9c96411b5fea006f2097e4">FLASH_QUERY_IMPL_DECODE</references>
        <referencedby refid="ckernel__orchestration_8h_1a745d032ebb518826e284b4a3680a8cb5" compoundref="ckernel__orchestration_8c" startline="1040" endline="1196">ck_layer_forward_rmsnorm_swiglu_decode</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1ab8d674c4a63b69a0cc0b38bbe58fa9f2" compoundref="ckernel__orchestration_8c" startline="1198" endline="1349">ck_layer_forward_rmsnorm_swiglu_decode_fused</referencedby>
        <referencedby refid="attention__decode__fused_8c_1a1e6628f9f140c9749a6dd7c2c9ce263a" compoundref="attention__decode__fused_8c" startline="165" endline="323">ck_layer_forward_rmsnorm_swiglu_decode_fused_attn_impl</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1abb01994013418ff7b8be71dc9bdcded5" compoundref="ckernel__orchestration_8c" startline="1601" endline="1870">ck_layer_forward_rmsnorm_swiglu_decode_q4_k</referencedby>
        <referencedby refid="ckernel__orchestration_8h_1ae07680f1a438bd1824fa4b1c3e4e826e" compoundref="ckernel__orchestration_8c" startline="1982" endline="2152">ck_layer_forward_rmsnorm_swiglu_decode_quant</referencedby>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" prot="public" static="yes" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>float *</type>
        <definition>static float* convert_bf16_tensor</definition>
        <argsstring>(const uint16_t *src, size_t count)</argsstring>
        <name>convert_bf16_tensor</name>
        <param>
          <type>const uint16_t *</type>
          <declname>src</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>count</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="10" column="14" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="10" bodyend="19"/>
        <references refid="bf16__utils_8h_1a94c0b1e3b43eb46dcce37900ed5c1333" compoundref="bf16__utils_8h" startline="250" endline="266">bf16_tensor_to_float</references>
        <referencedby refid="ckernel__engine_8h_1a1a95c2e93bfbe603df487d0c0eb5ea2b" compoundref="attention__kernels_8c" startline="884" endline="940">attention_backward_causal_head_major_gqa_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1af749b0ec6a9cc8a63033fa2069759722" compoundref="attention__kernels_8c" startline="319" endline="359">attention_forward_causal_head_major_gqa_bf16</referencedby>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>size_t</type>
        <definition>static size_t qkv_index</definition>
        <argsstring>(int h, int t, int d, int num_tokens, int aligned_head_dim)</argsstring>
        <name>qkv_index</name>
        <param>
          <type>int</type>
          <declname>h</declname>
        </param>
        <param>
          <type>int</type>
          <declname>t</declname>
        </param>
        <param>
          <type>int</type>
          <declname>d</declname>
        </param>
        <param>
          <type>int</type>
          <declname>num_tokens</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_head_dim</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="23" column="22" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="23" bodyend="31"/>
        <referencedby refid="ckernel__engine_8h_1adbd2b55fbc53b6e288c98813b61cd6e3" compoundref="attention__kernels_8c" startline="942" endline="1068">attention_backward_causal_head_major_gqa</referencedby>
        <referencedby refid="ckernel__engine_8h_1a3d8664b9e0808546484af9ec7d4ddfe1" compoundref="attention__kernels_8c" startline="59" endline="123">attention_forward_causal_head_major</referencedby>
        <referencedby refid="ckernel__engine_8h_1a57b7a6f6f08b030fd8d5fbf87fa31ac7" compoundref="attention__kernels_8c" startline="127" endline="191">attention_forward_causal_head_major_exact</referencedby>
        <referencedby refid="ckernel__engine_8h_1a3e1aa7c55e515fd996318da27c2c5ade" compoundref="attention__kernels_8c" startline="195" endline="253">attention_forward_causal_head_major_gqa</referencedby>
        <referencedby refid="ckernel__engine_8h_1a04febaa686747fdfad9e915b627a0915" compoundref="attention__kernels_8c" startline="258" endline="317">attention_forward_causal_head_major_gqa_exact</referencedby>
        <referencedby refid="ckernel__engine_8h_1aac305a28084fe73b2264ae57613ba3ea" compoundref="attention__kernels_8c" startline="749" endline="796">attention_forward_causal_head_major_gqa_flash</referencedby>
      </memberdef>
      <memberdef kind="function" id="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>size_t</type>
        <definition>static size_t score_index</definition>
        <argsstring>(int h, int i, int j, int aligned_context_window)</argsstring>
        <name>score_index</name>
        <param>
          <type>int</type>
          <declname>h</declname>
        </param>
        <param>
          <type>int</type>
          <declname>i</declname>
        </param>
        <param>
          <type>int</type>
          <declname>j</declname>
        </param>
        <param>
          <type>int</type>
          <declname>aligned_context_window</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" line="35" column="22" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c" bodystart="35" bodyend="43"/>
        <referencedby refid="ckernel__engine_8h_1adbd2b55fbc53b6e288c98813b61cd6e3" compoundref="attention__kernels_8c" startline="942" endline="1068">attention_backward_causal_head_major_gqa</referencedby>
        <referencedby refid="ckernel__engine_8h_1a3d8664b9e0808546484af9ec7d4ddfe1" compoundref="attention__kernels_8c" startline="59" endline="123">attention_forward_causal_head_major</referencedby>
        <referencedby refid="ckernel__engine_8h_1a57b7a6f6f08b030fd8d5fbf87fa31ac7" compoundref="attention__kernels_8c" startline="127" endline="191">attention_forward_causal_head_major_exact</referencedby>
        <referencedby refid="ckernel__engine_8h_1a3e1aa7c55e515fd996318da27c2c5ade" compoundref="attention__kernels_8c" startline="195" endline="253">attention_forward_causal_head_major_gqa</referencedby>
        <referencedby refid="ckernel__engine_8h_1a04febaa686747fdfad9e915b627a0915" compoundref="attention__kernels_8c" startline="258" endline="317">attention_forward_causal_head_major_gqa_exact</referencedby>
      </memberdef>
      </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="preprocessor">#include<sp/>&quot;<ref refid="bf16__utils_8h" kindref="compound">bf16_utils.h</ref>&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&quot;<ref refid="ckernel__engine_8h" kindref="compound">ckernel_engine.h</ref>&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;math.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdlib.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX__)<sp/>||<sp/>defined(__AVX2__)<sp/>||<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;immintrin.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight></codeline>
<codeline lineno="10" refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*<ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*src,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>count)</highlight></codeline>
<codeline lineno="11"><highlight class="normal">{</highlight></codeline>
<codeline lineno="12"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*dst<sp/>=<sp/>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*)malloc(count<sp/>*<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));</highlight></codeline>
<codeline lineno="13"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!dst)<sp/>{</highlight></codeline>
<codeline lineno="14"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>NULL;</highlight></codeline>
<codeline lineno="15"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="16"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Use<sp/>vectorized<sp/>conversion<sp/>when<sp/>available<sp/>(AVX-512)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="bf16__utils_8h_1a94c0b1e3b43eb46dcce37900ed5c1333" kindref="member">bf16_tensor_to_float</ref>(src,<sp/>dst,<sp/>count);</highlight></codeline>
<codeline lineno="18"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>dst;</highlight></codeline>
<codeline lineno="19"><highlight class="normal">}</highlight></codeline>
<codeline lineno="20"><highlight class="normal"></highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Helpers<sp/>for<sp/>head-major<sp/>layouts<sp/>used<sp/>in<sp/>attention.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Q/K/V<sp/>layout:<sp/>[head][token][head_dim]<sp/>with<sp/>stride<sp/>aligned_head_dim.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="23" refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h,</highlight></codeline>
<codeline lineno="24"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>t,</highlight></codeline>
<codeline lineno="25"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d,</highlight></codeline>
<codeline lineno="26"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim)</highlight></codeline>
<codeline lineno="28"><highlight class="normal">{</highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>((</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)num_tokens<sp/>+<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)t)<sp/>*<sp/>(size_t)aligned_head_dim</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>+<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)d;</highlight></codeline>
<codeline lineno="31"><highlight class="normal">}</highlight></codeline>
<codeline lineno="32"><highlight class="normal"></highlight></codeline>
<codeline lineno="33"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Scores<sp/>layout<sp/>matches<sp/>causal_softmax_head_major:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="34"><highlight class="normal"></highlight><highlight class="comment">//<sp/>[head][query_token][key_token]<sp/>with<sp/>stride<sp/>aligned_context_window.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="35" refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h,</highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i,</highlight></codeline>
<codeline lineno="37"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j,</highlight></codeline>
<codeline lineno="38"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="39"><highlight class="normal">{</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>((</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_context_window<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_context_window)</highlight></codeline>
<codeline lineno="41"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>+<sp/>(size_t)i<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_context_window</highlight></codeline>
<codeline lineno="42"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>+<sp/>(size_t)j;</highlight></codeline>
<codeline lineno="43"><highlight class="normal">}</highlight></codeline>
<codeline lineno="44"><highlight class="normal"></highlight></codeline>
<codeline lineno="45"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Naive,<sp/>reference-quality<sp/>scaled<sp/>dot-product<sp/>attention<sp/>with<sp/>causal<sp/>mask.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="46"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="47"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Q,<sp/>K,<sp/>V<sp/>are<sp/>head-major:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="48"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>q[h,<sp/>t,<sp/>d]<sp/>at<sp/>q[h<sp/>*<sp/>T<sp/>*<sp/>aligned_head_dim<sp/>+<sp/>t<sp/>*<sp/>aligned_head_dim<sp/>+<sp/>d]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="49"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>same<sp/>for<sp/>k<sp/>and<sp/>v.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="50"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="51"><highlight class="normal"></highlight><highlight class="comment">//<sp/>scores<sp/>buffer<sp/>must<sp/>be<sp/>at<sp/>least:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="52"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>num_heads<sp/>*<sp/>aligned_context_window<sp/>*<sp/>aligned_context_window<sp/>floats.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="53"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight><highlight class="comment">//<sp/>output<sp/>has<sp/>same<sp/>layout<sp/>as<sp/>Q/V:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="55"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>out[h,<sp/>t,<sp/>d]<sp/>at<sp/>out[h<sp/>*<sp/>T<sp/>*<sp/>aligned_head_dim<sp/>+<sp/>t<sp/>*<sp/>aligned_head_dim<sp/>+<sp/>d]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="56"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="57"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Only<sp/>the<sp/>first<sp/>head_dim<sp/>elements<sp/>of<sp/>each<sp/>vector<sp/>participate<sp/>in<sp/>the<sp/>math;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="58"><highlight class="normal"></highlight><highlight class="comment">//<sp/>aligned_head_dim<sp/>allows<sp/>callers<sp/>to<sp/>pad<sp/>to<sp/>cache-friendly<sp/>widths.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="59" refid="ckernel__engine_8h_1a3d8664b9e0808546484af9ec7d4ddfe1" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a3d8664b9e0808546484af9ec7d4ddfe1" kindref="member">attention_forward_causal_head_major</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q,</highlight></codeline>
<codeline lineno="60"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k,</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*scores,</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*output,</highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="69"><highlight class="normal">{</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>1.0f<sp/>/<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)head_dim);</highlight></codeline>
<codeline lineno="71"><highlight class="normal"></highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Phase<sp/>1:<sp/>compute<sp/>scaled<sp/>dot-product<sp/>scores<sp/>QK^T<sp/>/<sp/>sqrt(d_k),</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>lower<sp/>triangle<sp/>only<sp/>(j<sp/>&lt;=<sp/>i).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_q<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_k<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="80"><highlight class="normal"></highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q[base_q<sp/>+<sp/>d]<sp/>*<sp/>k[base_k<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="84"><highlight class="normal"></highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="86"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="87"><highlight class="normal"></highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Ensure<sp/>upper<sp/>triangle<sp/>is<sp/>zeroed<sp/>so<sp/>there<sp/>are<sp/>no<sp/>stale<sp/>values</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>before<sp/>the<sp/>softmax<sp/>kernel<sp/>runs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="90"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>i<sp/>+<sp/>1;<sp/>j<sp/>&lt;<sp/>num_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="91"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="92"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="95"><highlight class="normal"></highlight></codeline>
<codeline lineno="96"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Phase<sp/>2:<sp/>apply<sp/>causal<sp/>row-wise<sp/>softmax<sp/>in-place<sp/>over<sp/>j<sp/>&lt;=<sp/>i.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="ckernel__engine_8h_1a920868f80137fe3e0c9cd11acb7ba567" kindref="member">causal_softmax_head_major</ref>(scores,</highlight></codeline>
<codeline lineno="98"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_heads,</highlight></codeline>
<codeline lineno="99"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_tokens,</highlight></codeline>
<codeline lineno="100"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>aligned_context_window);</highlight></codeline>
<codeline lineno="101"><highlight class="normal"></highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Phase<sp/>3:<sp/>attention<sp/>weights<sp/><sp/>V.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="103"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="105"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>out_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="106"><highlight class="normal"></highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero<sp/>the<sp/>full<sp/>aligned<sp/>head<sp/>slice<sp/>so<sp/>padded<sp/>dims<sp/>stay<sp/>clean.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="111"><highlight class="normal"></highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Weighted<sp/>sum<sp/>over<sp/>causal<sp/>positions.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)];</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>v_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="116"><highlight class="normal"></highlight></codeline>
<codeline lineno="117"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>+=<sp/>w<sp/>*<sp/>v[v_base<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="119"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="122"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="123"><highlight class="normal">}</highlight></codeline>
<codeline lineno="124"><highlight class="normal"></highlight></codeline>
<codeline lineno="125"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Exact<sp/>version<sp/>using<sp/>standard<sp/>library<sp/>expf<sp/>for<sp/>softmax.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="126"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Slower<sp/>but<sp/>provides<sp/>maximum<sp/>accuracy<sp/>-<sp/>used<sp/>for<sp/>accuracy<sp/>testing.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="127" refid="ckernel__engine_8h_1a57b7a6f6f08b030fd8d5fbf87fa31ac7" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a57b7a6f6f08b030fd8d5fbf87fa31ac7" kindref="member">attention_forward_causal_head_major_exact</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q,</highlight></codeline>
<codeline lineno="128"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k,</highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,</highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*scores,</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*output,</highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="137"><highlight class="normal">{</highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>1.0f<sp/>/<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)head_dim);</highlight></codeline>
<codeline lineno="139"><highlight class="normal"></highlight></codeline>
<codeline lineno="140"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Phase<sp/>1:<sp/>compute<sp/>scaled<sp/>dot-product<sp/>scores<sp/>QK^T<sp/>/<sp/>sqrt(d_k),</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>lower<sp/>triangle<sp/>only<sp/>(j<sp/>&lt;=<sp/>i).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="145"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_q<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_k<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="148"><highlight class="normal"></highlight></codeline>
<codeline lineno="149"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q[base_q<sp/>+<sp/>d]<sp/>*<sp/>k[base_k<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="152"><highlight class="normal"></highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="155"><highlight class="normal"></highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Ensure<sp/>upper<sp/>triangle<sp/>is<sp/>zeroed<sp/>so<sp/>there<sp/>are<sp/>no<sp/>stale<sp/>values</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>before<sp/>the<sp/>softmax<sp/>kernel<sp/>runs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="158"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>i<sp/>+<sp/>1;<sp/>j<sp/>&lt;<sp/>num_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="162"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="163"><highlight class="normal"></highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Phase<sp/>2:<sp/>apply<sp/>causal<sp/>row-wise<sp/>softmax<sp/>using<sp/>exact<sp/>expf.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="ckernel__engine_8h_1a6ea7267298ef550524a6277b817a8ffb" kindref="member">causal_softmax_head_major_exact</ref>(scores,</highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_heads,</highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_tokens,</highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>aligned_context_window);</highlight></codeline>
<codeline lineno="169"><highlight class="normal"></highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Phase<sp/>3:<sp/>attention<sp/>weights<sp/><sp/>V.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="173"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>out_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="174"><highlight class="normal"></highlight></codeline>
<codeline lineno="175"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero<sp/>the<sp/>full<sp/>aligned<sp/>head<sp/>slice<sp/>so<sp/>padded<sp/>dims<sp/>stay<sp/>clean.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="179"><highlight class="normal"></highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Weighted<sp/>sum<sp/>over<sp/>causal<sp/>positions.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="181"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="182"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)];</highlight></codeline>
<codeline lineno="183"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>v_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="184"><highlight class="normal"></highlight></codeline>
<codeline lineno="185"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="186"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>+=<sp/>w<sp/>*<sp/>v[v_base<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="187"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="188"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="189"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="190"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="191"><highlight class="normal">}</highlight></codeline>
<codeline lineno="192"><highlight class="normal"></highlight></codeline>
<codeline lineno="193"><highlight class="normal"></highlight><highlight class="comment">//<sp/>GQA-aware<sp/>scaled<sp/>dot-product<sp/>attention<sp/>with<sp/>causal<sp/>mask.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="194"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Q<sp/>has<sp/>num_heads;<sp/>K/V<sp/>have<sp/>num_kv_heads.<sp/>Each<sp/>query<sp/>head<sp/>maps<sp/>to<sp/>a<sp/>KV<sp/>head.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="195" refid="ckernel__engine_8h_1a3e1aa7c55e515fd996318da27c2c5ade" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a3e1aa7c55e515fd996318da27c2c5ade" kindref="member">attention_forward_causal_head_major_gqa</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q,</highlight></codeline>
<codeline lineno="196"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k,</highlight></codeline>
<codeline lineno="197"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,</highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*scores,</highlight></codeline>
<codeline lineno="199"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*output,</highlight></codeline>
<codeline lineno="200"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="201"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="202"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="203"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="204"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="206"><highlight class="normal">{</highlight></codeline>
<codeline lineno="207"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>1.0f<sp/>/<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)head_dim);</highlight></codeline>
<codeline lineno="208"><highlight class="normal"></highlight></codeline>
<codeline lineno="209"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="210"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_head<sp/>=<sp/>(int)((</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/>long)num_kv_heads<sp/>/<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)num_heads);</highlight></codeline>
<codeline lineno="211"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="213"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="214"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_q<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="215"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_k<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(kv_head,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="216"><highlight class="normal"></highlight></codeline>
<codeline lineno="217"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="218"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q[base_q<sp/>+<sp/>d]<sp/>*<sp/>k[base_k<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="219"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="220"><highlight class="normal"></highlight></codeline>
<codeline lineno="221"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="222"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="223"><highlight class="normal"></highlight></codeline>
<codeline lineno="224"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>i<sp/>+<sp/>1;<sp/>j<sp/>&lt;<sp/>num_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="225"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="226"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="227"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="228"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="229"><highlight class="normal"></highlight></codeline>
<codeline lineno="230"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="ckernel__engine_8h_1a920868f80137fe3e0c9cd11acb7ba567" kindref="member">causal_softmax_head_major</ref>(scores,</highlight></codeline>
<codeline lineno="231"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_heads,</highlight></codeline>
<codeline lineno="232"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_tokens,</highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>aligned_context_window);</highlight></codeline>
<codeline lineno="234"><highlight class="normal"></highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="236"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_head<sp/>=<sp/>(int)((</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/>long)num_kv_heads<sp/>/<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)num_heads);</highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>out_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="241"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="242"><highlight class="normal"></highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="244"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)];</highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>v_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(kv_head,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="246"><highlight class="normal"></highlight></codeline>
<codeline lineno="247"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="248"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>+=<sp/>w<sp/>*<sp/>v[v_base<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="249"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="250"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="251"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="252"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="253"><highlight class="normal">}</highlight></codeline>
<codeline lineno="254"><highlight class="normal"></highlight></codeline>
<codeline lineno="255"><highlight class="normal"></highlight><highlight class="comment">//<sp/>GQA<sp/>attention<sp/>forward<sp/>using<sp/>exact<sp/>softmax<sp/>(standard<sp/>library<sp/>expf).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="256"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Slower<sp/>but<sp/>provides<sp/>maximum<sp/>accuracy.<sp/>Used<sp/>by<sp/>BF16<sp/>wrapper<sp/>to<sp/>avoid</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="257"><highlight class="normal"></highlight><highlight class="comment">//<sp/>approximation<sp/>error<sp/>accumulating<sp/>with<sp/>BF16<sp/>precision<sp/>loss.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="258" refid="ckernel__engine_8h_1a04febaa686747fdfad9e915b627a0915" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a04febaa686747fdfad9e915b627a0915" kindref="member">attention_forward_causal_head_major_gqa_exact</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q,</highlight></codeline>
<codeline lineno="259"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k,</highlight></codeline>
<codeline lineno="260"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,</highlight></codeline>
<codeline lineno="261"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*scores,</highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*output,</highlight></codeline>
<codeline lineno="263"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="266"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="268"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="269"><highlight class="normal">{</highlight></codeline>
<codeline lineno="270"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>1.0f<sp/>/<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)head_dim);</highlight></codeline>
<codeline lineno="271"><highlight class="normal"></highlight></codeline>
<codeline lineno="272"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="273"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_head<sp/>=<sp/>(int)((</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/>long)num_kv_heads<sp/>/<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)num_heads);</highlight></codeline>
<codeline lineno="274"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="275"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="276"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="277"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_q<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="278"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>base_k<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(kv_head,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="279"><highlight class="normal"></highlight></codeline>
<codeline lineno="280"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="281"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q[base_q<sp/>+<sp/>d]<sp/>*<sp/>k[base_k<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="282"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="283"><highlight class="normal"></highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="286"><highlight class="normal"></highlight></codeline>
<codeline lineno="287"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>i<sp/>+<sp/>1;<sp/>j<sp/>&lt;<sp/>num_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="288"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="290"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="292"><highlight class="normal"></highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Use<sp/>exact<sp/>softmax<sp/>with<sp/>standard<sp/>library<sp/>expf</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="ckernel__engine_8h_1a6ea7267298ef550524a6277b817a8ffb" kindref="member">causal_softmax_head_major_exact</ref>(scores,</highlight></codeline>
<codeline lineno="295"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_heads,</highlight></codeline>
<codeline lineno="296"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_tokens,</highlight></codeline>
<codeline lineno="297"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>aligned_context_window);</highlight></codeline>
<codeline lineno="298"><highlight class="normal"></highlight></codeline>
<codeline lineno="299"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="300"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_head<sp/>=<sp/>(int)((</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/>long)num_kv_heads<sp/>/<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)num_heads);</highlight></codeline>
<codeline lineno="301"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>num_tokens;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="302"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>out_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="303"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="304"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="305"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="306"><highlight class="normal"></highlight></codeline>
<codeline lineno="307"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="308"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/>scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aligned_context_window)];</highlight></codeline>
<codeline lineno="309"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>v_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(kv_head,<sp/>j,<sp/>0,<sp/>num_tokens,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="310"><highlight class="normal"></highlight></codeline>
<codeline lineno="311"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="312"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output[out_base<sp/>+<sp/>d]<sp/>+=<sp/>w<sp/>*<sp/>v[v_base<sp/>+<sp/>d];</highlight></codeline>
<codeline lineno="313"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="314"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="315"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="316"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="317"><highlight class="normal">}</highlight></codeline>
<codeline lineno="318"><highlight class="normal"></highlight></codeline>
<codeline lineno="319" refid="ckernel__engine_8h_1af749b0ec6a9cc8a63033fa2069759722" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1af749b0ec6a9cc8a63033fa2069759722" kindref="member">attention_forward_causal_head_major_gqa_bf16</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*q,</highlight></codeline>
<codeline lineno="320"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*k,</highlight></codeline>
<codeline lineno="321"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*v,</highlight></codeline>
<codeline lineno="322"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*scores,</highlight></codeline>
<codeline lineno="323"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*output,</highlight></codeline>
<codeline lineno="324"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="325"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="326"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="327"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="328"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="329"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="330"><highlight class="normal">{</highlight></codeline>
<codeline lineno="331"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>q_elems<sp/>=<sp/>(size_t)num_heads<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)num_tokens<sp/>*<sp/>(size_t)aligned_head_dim;</highlight></codeline>
<codeline lineno="332"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>kv_elems<sp/>=<sp/>(size_t)num_kv_heads<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)num_tokens<sp/>*<sp/>(size_t)aligned_head_dim;</highlight></codeline>
<codeline lineno="333"><highlight class="normal"></highlight></codeline>
<codeline lineno="334"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_float<sp/>=<sp/><ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(q,<sp/>q_elems);</highlight></codeline>
<codeline lineno="335"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!q_float)<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="336"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_float<sp/>=<sp/><ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(k,<sp/>kv_elems);</highlight></codeline>
<codeline lineno="337"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!k_float)<sp/>{</highlight></codeline>
<codeline lineno="338"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(q_float);</highlight></codeline>
<codeline lineno="339"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="340"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="341"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_float<sp/>=<sp/><ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(v,<sp/>kv_elems);</highlight></codeline>
<codeline lineno="342"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!v_float)<sp/>{</highlight></codeline>
<codeline lineno="343"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(q_float);</highlight></codeline>
<codeline lineno="344"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(k_float);</highlight></codeline>
<codeline lineno="345"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="346"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="347"><highlight class="normal"></highlight></codeline>
<codeline lineno="348"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Use<sp/>exact<sp/>version<sp/>to<sp/>avoid<sp/>fast<sp/>exp<sp/>approximation<sp/>error<sp/>accumulating</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="349"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>with<sp/>BF16<sp/>precision<sp/>loss.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="350"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="attention__kernels_8c_1a04febaa686747fdfad9e915b627a0915" kindref="member">attention_forward_causal_head_major_gqa_exact</ref>(q_float,<sp/>k_float,<sp/>v_float,</highlight></codeline>
<codeline lineno="351"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scores,<sp/>output,</highlight></codeline>
<codeline lineno="352"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_heads,<sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="353"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_tokens,<sp/>head_dim,</highlight></codeline>
<codeline lineno="354"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>aligned_head_dim,<sp/>aligned_context_window);</highlight></codeline>
<codeline lineno="355"><highlight class="normal"></highlight></codeline>
<codeline lineno="356"><highlight class="normal"><sp/><sp/><sp/><sp/>free(q_float);</highlight></codeline>
<codeline lineno="357"><highlight class="normal"><sp/><sp/><sp/><sp/>free(k_float);</highlight></codeline>
<codeline lineno="358"><highlight class="normal"><sp/><sp/><sp/><sp/>free(v_float);</highlight></codeline>
<codeline lineno="359"><highlight class="normal">}</highlight></codeline>
<codeline lineno="360"><highlight class="normal"></highlight></codeline>
<codeline lineno="361"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="362"><highlight class="normal"></highlight><highlight class="comment">//<sp/>ATTENTION<sp/>FORWARD<sp/>-<sp/>Flash-style<sp/>(no<sp/>scores<sp/>materialization)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="363"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="364"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="365"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Computes<sp/>the<sp/>same<sp/>causal<sp/>attention<sp/>output<sp/>as<sp/>`attention_forward_causal_head_major_gqa`,</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="366"><highlight class="normal"></highlight><highlight class="comment">//<sp/>but<sp/>does<sp/>not<sp/>materialize<sp/>the<sp/>[H,<sp/>T,<sp/>T]<sp/>score/weight<sp/>matrices.<sp/>This<sp/>is<sp/>useful<sp/>for:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="367"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Prefill:<sp/>avoids<sp/>large<sp/>scratch<sp/>buffers<sp/>and<sp/>improves<sp/>cache<sp/>locality</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="368"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Decode:<sp/>supports<sp/>KV-cache<sp/>attention<sp/>for<sp/>a<sp/>single<sp/>token</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="369"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="370"><highlight class="normal"></highlight><highlight class="comment">//<sp/>SIMD-optimized<sp/>implementations<sp/>for<sp/>AVX-512,<sp/>AVX2,<sp/>and<sp/>AVX<sp/>follow.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="371"><highlight class="normal"></highlight></codeline>
<codeline lineno="372"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="373"><highlight class="normal"></highlight><highlight class="comment">//<sp/>AVX-512<sp/>SIMD<sp/>Flash<sp/>Attention<sp/>(16<sp/>floats<sp/>per<sp/>vector)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="374"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="375"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="376"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>attention_flash_query_causal_avx512(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_vec,</highlight></codeline>
<codeline lineno="377"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_head,</highlight></codeline>
<codeline lineno="378"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_head,</highlight></codeline>
<codeline lineno="379"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_tokens,</highlight></codeline>
<codeline lineno="380"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="381"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="382"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale,</highlight></codeline>
<codeline lineno="383"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out_vec)</highlight></codeline>
<codeline lineno="384"><highlight class="normal">{</highlight></codeline>
<codeline lineno="385"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Online<sp/>softmax:<sp/>m<sp/>=<sp/>running<sp/>max,<sp/>s<sp/>=<sp/>running<sp/>sum(exp(score<sp/>-<sp/>m))</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="386"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>m<sp/>=<sp/>-INFINITY;</highlight></codeline>
<codeline lineno="387"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>s<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="388"><highlight class="normal"></highlight></codeline>
<codeline lineno="389"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero<sp/>output<sp/>using<sp/>SIMD</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="390"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="391"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>16<sp/>&lt;=<sp/>aligned_head_dim;<sp/>d<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="392"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;out_vec[d],<sp/>_mm512_setzero_ps());</highlight></codeline>
<codeline lineno="393"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="394"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="395"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="396"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="397"><highlight class="normal"></highlight></codeline>
<codeline lineno="398"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;<sp/>kv_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="399"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_vec<sp/>=<sp/>k_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="400"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_vec<sp/>=<sp/>v_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="401"><highlight class="normal"></highlight></codeline>
<codeline lineno="402"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Vectorized<sp/>dot<sp/>product<sp/>QK</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="403"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>dot_acc<sp/>=<sp/>_mm512_setzero_ps();</highlight></codeline>
<codeline lineno="404"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="405"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>16<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="406"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>q_v<sp/>=<sp/>_mm512_loadu_ps(&amp;q_vec[d]);</highlight></codeline>
<codeline lineno="407"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>k_v<sp/>=<sp/>_mm512_loadu_ps(&amp;k_vec[d]);</highlight></codeline>
<codeline lineno="408"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot_acc<sp/>=<sp/>_mm512_fmadd_ps(q_v,<sp/>k_v,<sp/>dot_acc);</highlight></codeline>
<codeline lineno="409"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="410"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>_mm512_reduce_add_ps(dot_acc);</highlight></codeline>
<codeline lineno="411"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Scalar<sp/>tail</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="412"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="413"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q_vec[d]<sp/>*<sp/>k_vec[d];</highlight></codeline>
<codeline lineno="414"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="415"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>score<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="416"><highlight class="normal"></highlight></codeline>
<codeline lineno="417"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(score<sp/>&gt;<sp/>m)<sp/>{</highlight></codeline>
<codeline lineno="418"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>exp_m<sp/>=<sp/>(m<sp/>==<sp/>-INFINITY)<sp/>?<sp/>0.0f<sp/>:<sp/>expf(m<sp/>-<sp/>score);</highlight></codeline>
<codeline lineno="419"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>*=<sp/>exp_m;</highlight></codeline>
<codeline lineno="420"><highlight class="normal"></highlight></codeline>
<codeline lineno="421"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Vectorized:<sp/>out<sp/>*=<sp/>exp_m,<sp/>then<sp/>out<sp/>+=<sp/>v</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="422"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>exp_m_vec<sp/>=<sp/>_mm512_set1_ps(exp_m);</highlight></codeline>
<codeline lineno="423"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="424"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>16<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="425"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>out_v<sp/>=<sp/>_mm512_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="426"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>v_v<sp/>=<sp/>_mm512_loadu_ps(&amp;v_vec[d]);</highlight></codeline>
<codeline lineno="427"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_v<sp/>=<sp/>_mm512_fmadd_ps(out_v,<sp/>exp_m_vec,<sp/>v_v);</highlight></codeline>
<codeline lineno="428"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;out_vec[d],<sp/>out_v);</highlight></codeline>
<codeline lineno="429"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="430"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="431"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>out_vec[d]<sp/>*<sp/>exp_m<sp/>+<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="432"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="433"><highlight class="normal"></highlight></codeline>
<codeline lineno="434"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>1.0f;</highlight></codeline>
<codeline lineno="435"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m<sp/>=<sp/>score;</highlight></codeline>
<codeline lineno="436"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="437"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>e<sp/>=<sp/>expf(score<sp/>-<sp/>m);</highlight></codeline>
<codeline lineno="438"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>e;</highlight></codeline>
<codeline lineno="439"><highlight class="normal"></highlight></codeline>
<codeline lineno="440"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Vectorized:<sp/>out<sp/>+=<sp/>e<sp/>*<sp/>v</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="441"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>e_vec<sp/>=<sp/>_mm512_set1_ps(e);</highlight></codeline>
<codeline lineno="442"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="443"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>16<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="444"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>out_v<sp/>=<sp/>_mm512_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="445"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>v_v<sp/>=<sp/>_mm512_loadu_ps(&amp;v_vec[d]);</highlight></codeline>
<codeline lineno="446"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_v<sp/>=<sp/>_mm512_fmadd_ps(e_vec,<sp/>v_v,<sp/>out_v);</highlight></codeline>
<codeline lineno="447"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;out_vec[d],<sp/>out_v);</highlight></codeline>
<codeline lineno="448"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="449"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="450"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>+=<sp/>e<sp/>*<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="451"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="452"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="453"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="454"><highlight class="normal"></highlight></codeline>
<codeline lineno="455"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Normalize:<sp/>out<sp/>/=<sp/>s</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="456"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>inv_s<sp/>=<sp/>1.0f<sp/>/<sp/>s;</highlight></codeline>
<codeline lineno="457"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>inv_s_vec<sp/>=<sp/>_mm512_set1_ps(inv_s);</highlight></codeline>
<codeline lineno="458"><highlight class="normal"><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="459"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>16<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="460"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>out_v<sp/>=<sp/>_mm512_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="461"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;out_vec[d],<sp/>_mm512_mul_ps(out_v,<sp/>inv_s_vec));</highlight></codeline>
<codeline lineno="462"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="463"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="464"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>*=<sp/>inv_s;</highlight></codeline>
<codeline lineno="465"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="466"><highlight class="normal"></highlight></codeline>
<codeline lineno="467"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero<sp/>padding</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="468"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>head_dim;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="469"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="470"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="471"><highlight class="normal">}</highlight></codeline>
<codeline lineno="472"><highlight class="normal"></highlight><highlight class="preprocessor">#endif<sp/></highlight><highlight class="comment">//<sp/>__AVX512F__</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="473"><highlight class="normal"></highlight></codeline>
<codeline lineno="474"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="475"><highlight class="normal"></highlight><highlight class="comment">//<sp/>AVX2<sp/>SIMD<sp/>Flash<sp/>Attention<sp/>(8<sp/>floats<sp/>per<sp/>vector)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="476"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="477"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX2__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="478"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>hsum256_ps_flash(__m256<sp/>v)<sp/>{</highlight></codeline>
<codeline lineno="479"><highlight class="normal"><sp/><sp/><sp/><sp/>__m128<sp/>hi<sp/>=<sp/>_mm256_extractf128_ps(v,<sp/>1);</highlight></codeline>
<codeline lineno="480"><highlight class="normal"><sp/><sp/><sp/><sp/>__m128<sp/>lo<sp/>=<sp/>_mm256_castps256_ps128(v);</highlight></codeline>
<codeline lineno="481"><highlight class="normal"><sp/><sp/><sp/><sp/>__m128<sp/>sum128<sp/>=<sp/>_mm_add_ps(lo,<sp/>hi);</highlight></codeline>
<codeline lineno="482"><highlight class="normal"><sp/><sp/><sp/><sp/>sum128<sp/>=<sp/>_mm_hadd_ps(sum128,<sp/>sum128);</highlight></codeline>
<codeline lineno="483"><highlight class="normal"><sp/><sp/><sp/><sp/>sum128<sp/>=<sp/>_mm_hadd_ps(sum128,<sp/>sum128);</highlight></codeline>
<codeline lineno="484"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>_mm_cvtss_f32(sum128);</highlight></codeline>
<codeline lineno="485"><highlight class="normal">}</highlight></codeline>
<codeline lineno="486"><highlight class="normal"></highlight></codeline>
<codeline lineno="487"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>attention_flash_query_causal_avx2(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_vec,</highlight></codeline>
<codeline lineno="488"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_head,</highlight></codeline>
<codeline lineno="489"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_head,</highlight></codeline>
<codeline lineno="490"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_tokens,</highlight></codeline>
<codeline lineno="491"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="492"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="493"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale,</highlight></codeline>
<codeline lineno="494"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out_vec)</highlight></codeline>
<codeline lineno="495"><highlight class="normal">{</highlight></codeline>
<codeline lineno="496"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>m<sp/>=<sp/>-INFINITY;</highlight></codeline>
<codeline lineno="497"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>s<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="498"><highlight class="normal"></highlight></codeline>
<codeline lineno="499"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero<sp/>output<sp/>using<sp/>SIMD</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="500"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="501"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>aligned_head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="502"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>_mm256_setzero_ps());</highlight></codeline>
<codeline lineno="503"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="504"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="505"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="506"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="507"><highlight class="normal"></highlight></codeline>
<codeline lineno="508"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;<sp/>kv_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="509"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_vec<sp/>=<sp/>k_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="510"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_vec<sp/>=<sp/>v_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="511"><highlight class="normal"></highlight></codeline>
<codeline lineno="512"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Vectorized<sp/>dot<sp/>product<sp/>QK</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="513"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>dot_acc<sp/>=<sp/>_mm256_setzero_ps();</highlight></codeline>
<codeline lineno="514"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="515"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="516"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>q_v<sp/>=<sp/>_mm256_loadu_ps(&amp;q_vec[d]);</highlight></codeline>
<codeline lineno="517"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>k_v<sp/>=<sp/>_mm256_loadu_ps(&amp;k_vec[d]);</highlight></codeline>
<codeline lineno="518"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot_acc<sp/>=<sp/>_mm256_fmadd_ps(q_v,<sp/>k_v,<sp/>dot_acc);</highlight></codeline>
<codeline lineno="519"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="520"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>hsum256_ps_flash(dot_acc);</highlight></codeline>
<codeline lineno="521"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="522"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q_vec[d]<sp/>*<sp/>k_vec[d];</highlight></codeline>
<codeline lineno="523"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="524"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>score<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="525"><highlight class="normal"></highlight></codeline>
<codeline lineno="526"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(score<sp/>&gt;<sp/>m)<sp/>{</highlight></codeline>
<codeline lineno="527"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>exp_m<sp/>=<sp/>(m<sp/>==<sp/>-INFINITY)<sp/>?<sp/>0.0f<sp/>:<sp/>expf(m<sp/>-<sp/>score);</highlight></codeline>
<codeline lineno="528"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>*=<sp/>exp_m;</highlight></codeline>
<codeline lineno="529"><highlight class="normal"></highlight></codeline>
<codeline lineno="530"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>exp_m_vec<sp/>=<sp/>_mm256_set1_ps(exp_m);</highlight></codeline>
<codeline lineno="531"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="532"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="533"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>out_v<sp/>=<sp/>_mm256_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="534"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>v_v<sp/>=<sp/>_mm256_loadu_ps(&amp;v_vec[d]);</highlight></codeline>
<codeline lineno="535"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_v<sp/>=<sp/>_mm256_fmadd_ps(out_v,<sp/>exp_m_vec,<sp/>v_v);</highlight></codeline>
<codeline lineno="536"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>out_v);</highlight></codeline>
<codeline lineno="537"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="538"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="539"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>out_vec[d]<sp/>*<sp/>exp_m<sp/>+<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="540"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="541"><highlight class="normal"></highlight></codeline>
<codeline lineno="542"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>1.0f;</highlight></codeline>
<codeline lineno="543"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m<sp/>=<sp/>score;</highlight></codeline>
<codeline lineno="544"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="545"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>e<sp/>=<sp/>expf(score<sp/>-<sp/>m);</highlight></codeline>
<codeline lineno="546"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>e;</highlight></codeline>
<codeline lineno="547"><highlight class="normal"></highlight></codeline>
<codeline lineno="548"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>e_vec<sp/>=<sp/>_mm256_set1_ps(e);</highlight></codeline>
<codeline lineno="549"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="550"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="551"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>out_v<sp/>=<sp/>_mm256_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="552"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>v_v<sp/>=<sp/>_mm256_loadu_ps(&amp;v_vec[d]);</highlight></codeline>
<codeline lineno="553"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_v<sp/>=<sp/>_mm256_fmadd_ps(e_vec,<sp/>v_v,<sp/>out_v);</highlight></codeline>
<codeline lineno="554"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>out_v);</highlight></codeline>
<codeline lineno="555"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="556"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="557"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>+=<sp/>e<sp/>*<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="558"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="559"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="560"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="561"><highlight class="normal"></highlight></codeline>
<codeline lineno="562"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Normalize</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="563"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>inv_s<sp/>=<sp/>1.0f<sp/>/<sp/>s;</highlight></codeline>
<codeline lineno="564"><highlight class="normal"><sp/><sp/><sp/><sp/>__m256<sp/>inv_s_vec<sp/>=<sp/>_mm256_set1_ps(inv_s);</highlight></codeline>
<codeline lineno="565"><highlight class="normal"><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="566"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="567"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>out_v<sp/>=<sp/>_mm256_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="568"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>_mm256_mul_ps(out_v,<sp/>inv_s_vec));</highlight></codeline>
<codeline lineno="569"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="570"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="571"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>*=<sp/>inv_s;</highlight></codeline>
<codeline lineno="572"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="573"><highlight class="normal"></highlight></codeline>
<codeline lineno="574"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>head_dim;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="575"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="576"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="577"><highlight class="normal">}</highlight></codeline>
<codeline lineno="578"><highlight class="normal"></highlight><highlight class="preprocessor">#endif<sp/></highlight><highlight class="comment">//<sp/>__AVX2__</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="579"><highlight class="normal"></highlight></codeline>
<codeline lineno="580"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="581"><highlight class="normal"></highlight><highlight class="comment">//<sp/>AVX<sp/>SIMD<sp/>Flash<sp/>Attention<sp/>(8<sp/>floats<sp/>per<sp/>vector,<sp/>no<sp/>FMA)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="582"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="583"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX__)<sp/>&amp;&amp;<sp/>!defined(__AVX2__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="584"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>hsum256_ps_flash_avx(__m256<sp/>v)<sp/>{</highlight></codeline>
<codeline lineno="585"><highlight class="normal"><sp/><sp/><sp/><sp/>__m128<sp/>hi<sp/>=<sp/>_mm256_extractf128_ps(v,<sp/>1);</highlight></codeline>
<codeline lineno="586"><highlight class="normal"><sp/><sp/><sp/><sp/>__m128<sp/>lo<sp/>=<sp/>_mm256_castps256_ps128(v);</highlight></codeline>
<codeline lineno="587"><highlight class="normal"><sp/><sp/><sp/><sp/>__m128<sp/>sum128<sp/>=<sp/>_mm_add_ps(lo,<sp/>hi);</highlight></codeline>
<codeline lineno="588"><highlight class="normal"><sp/><sp/><sp/><sp/>sum128<sp/>=<sp/>_mm_hadd_ps(sum128,<sp/>sum128);</highlight></codeline>
<codeline lineno="589"><highlight class="normal"><sp/><sp/><sp/><sp/>sum128<sp/>=<sp/>_mm_hadd_ps(sum128,<sp/>sum128);</highlight></codeline>
<codeline lineno="590"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>_mm_cvtss_f32(sum128);</highlight></codeline>
<codeline lineno="591"><highlight class="normal">}</highlight></codeline>
<codeline lineno="592"><highlight class="normal"></highlight></codeline>
<codeline lineno="593"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>attention_flash_query_causal_avx(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_vec,</highlight></codeline>
<codeline lineno="594"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_head,</highlight></codeline>
<codeline lineno="595"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_head,</highlight></codeline>
<codeline lineno="596"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_tokens,</highlight></codeline>
<codeline lineno="597"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="598"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="599"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale,</highlight></codeline>
<codeline lineno="600"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out_vec)</highlight></codeline>
<codeline lineno="601"><highlight class="normal">{</highlight></codeline>
<codeline lineno="602"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>m<sp/>=<sp/>-INFINITY;</highlight></codeline>
<codeline lineno="603"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>s<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="604"><highlight class="normal"></highlight></codeline>
<codeline lineno="605"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero<sp/>output<sp/>using<sp/>SIMD</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="606"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="607"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>aligned_head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="608"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>_mm256_setzero_ps());</highlight></codeline>
<codeline lineno="609"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="610"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="611"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="612"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="613"><highlight class="normal"></highlight></codeline>
<codeline lineno="614"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;<sp/>kv_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="615"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_vec<sp/>=<sp/>k_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="616"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_vec<sp/>=<sp/>v_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="617"><highlight class="normal"></highlight></codeline>
<codeline lineno="618"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Vectorized<sp/>dot<sp/>product<sp/>QK<sp/>(no<sp/>FMA,<sp/>use<sp/>mul<sp/>+<sp/>add)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="619"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>dot_acc<sp/>=<sp/>_mm256_setzero_ps();</highlight></codeline>
<codeline lineno="620"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="621"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="622"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>q_v<sp/>=<sp/>_mm256_loadu_ps(&amp;q_vec[d]);</highlight></codeline>
<codeline lineno="623"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>k_v<sp/>=<sp/>_mm256_loadu_ps(&amp;k_vec[d]);</highlight></codeline>
<codeline lineno="624"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot_acc<sp/>=<sp/>_mm256_add_ps(dot_acc,<sp/>_mm256_mul_ps(q_v,<sp/>k_v));</highlight></codeline>
<codeline lineno="625"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="626"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>hsum256_ps_flash_avx(dot_acc);</highlight></codeline>
<codeline lineno="627"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="628"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q_vec[d]<sp/>*<sp/>k_vec[d];</highlight></codeline>
<codeline lineno="629"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="630"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>score<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="631"><highlight class="normal"></highlight></codeline>
<codeline lineno="632"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(score<sp/>&gt;<sp/>m)<sp/>{</highlight></codeline>
<codeline lineno="633"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>exp_m<sp/>=<sp/>(m<sp/>==<sp/>-INFINITY)<sp/>?<sp/>0.0f<sp/>:<sp/>expf(m<sp/>-<sp/>score);</highlight></codeline>
<codeline lineno="634"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>*=<sp/>exp_m;</highlight></codeline>
<codeline lineno="635"><highlight class="normal"></highlight></codeline>
<codeline lineno="636"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>exp_m_vec<sp/>=<sp/>_mm256_set1_ps(exp_m);</highlight></codeline>
<codeline lineno="637"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="638"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="639"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>out_v<sp/>=<sp/>_mm256_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="640"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>v_v<sp/>=<sp/>_mm256_loadu_ps(&amp;v_vec[d]);</highlight></codeline>
<codeline lineno="641"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>out<sp/>=<sp/>out<sp/>*<sp/>exp_m<sp/>+<sp/>v<sp/>(no<sp/>FMA)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="642"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_v<sp/>=<sp/>_mm256_add_ps(_mm256_mul_ps(out_v,<sp/>exp_m_vec),<sp/>v_v);</highlight></codeline>
<codeline lineno="643"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>out_v);</highlight></codeline>
<codeline lineno="644"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="645"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="646"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>out_vec[d]<sp/>*<sp/>exp_m<sp/>+<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="647"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="648"><highlight class="normal"></highlight></codeline>
<codeline lineno="649"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>1.0f;</highlight></codeline>
<codeline lineno="650"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m<sp/>=<sp/>score;</highlight></codeline>
<codeline lineno="651"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="652"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>e<sp/>=<sp/>expf(score<sp/>-<sp/>m);</highlight></codeline>
<codeline lineno="653"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>e;</highlight></codeline>
<codeline lineno="654"><highlight class="normal"></highlight></codeline>
<codeline lineno="655"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>e_vec<sp/>=<sp/>_mm256_set1_ps(e);</highlight></codeline>
<codeline lineno="656"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="657"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="658"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>out_v<sp/>=<sp/>_mm256_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="659"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>v_v<sp/>=<sp/>_mm256_loadu_ps(&amp;v_vec[d]);</highlight></codeline>
<codeline lineno="660"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>out<sp/>=<sp/>out<sp/>+<sp/>e<sp/>*<sp/>v<sp/>(no<sp/>FMA)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="661"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_v<sp/>=<sp/>_mm256_add_ps(out_v,<sp/>_mm256_mul_ps(e_vec,<sp/>v_v));</highlight></codeline>
<codeline lineno="662"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>out_v);</highlight></codeline>
<codeline lineno="663"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="664"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="665"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>+=<sp/>e<sp/>*<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="666"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="667"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="668"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="669"><highlight class="normal"></highlight></codeline>
<codeline lineno="670"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Normalize</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="671"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>inv_s<sp/>=<sp/>1.0f<sp/>/<sp/>s;</highlight></codeline>
<codeline lineno="672"><highlight class="normal"><sp/><sp/><sp/><sp/>__m256<sp/>inv_s_vec<sp/>=<sp/>_mm256_set1_ps(inv_s);</highlight></codeline>
<codeline lineno="673"><highlight class="normal"><sp/><sp/><sp/><sp/>d<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="674"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>+<sp/>8<sp/>&lt;=<sp/>head_dim;<sp/>d<sp/>+=<sp/>8)<sp/>{</highlight></codeline>
<codeline lineno="675"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m256<sp/>out_v<sp/>=<sp/>_mm256_loadu_ps(&amp;out_vec[d]);</highlight></codeline>
<codeline lineno="676"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm256_storeu_ps(&amp;out_vec[d],<sp/>_mm256_mul_ps(out_v,<sp/>inv_s_vec));</highlight></codeline>
<codeline lineno="677"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="678"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="679"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>*=<sp/>inv_s;</highlight></codeline>
<codeline lineno="680"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="681"><highlight class="normal"></highlight></codeline>
<codeline lineno="682"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(d<sp/>=<sp/>head_dim;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="683"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="684"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="685"><highlight class="normal">}</highlight></codeline>
<codeline lineno="686"><highlight class="normal"></highlight><highlight class="preprocessor">#endif<sp/></highlight><highlight class="comment">//<sp/>__AVX__<sp/>&amp;&amp;<sp/>!__AVX2__</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="687"><highlight class="normal"></highlight></codeline>
<codeline lineno="688"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="689"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Scalar<sp/>fallback<sp/>(original<sp/>implementation)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="690"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="691" refid="attention__kernels_8c_1aa09ace92ab625ae8365e61f47c3d93a5" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1aa09ace92ab625ae8365e61f47c3d93a5" kindref="member">attention_flash_query_causal</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_vec,</highlight></codeline>
<codeline lineno="692"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_head,</highlight></codeline>
<codeline lineno="693"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_head,</highlight></codeline>
<codeline lineno="694"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_tokens,</highlight></codeline>
<codeline lineno="695"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="696"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="697"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale,</highlight></codeline>
<codeline lineno="698"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out_vec)</highlight></codeline>
<codeline lineno="699"><highlight class="normal">{</highlight></codeline>
<codeline lineno="700"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Online<sp/>softmax:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="701"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/>m<sp/>=<sp/>running<sp/>max,<sp/>s<sp/>=<sp/>running<sp/>sum(exp(score<sp/>-<sp/>m))</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="702"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/>out<sp/>=<sp/>sum(exp(score<sp/>-<sp/>m)<sp/>*<sp/>v)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="703"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>m<sp/>=<sp/>-INFINITY;</highlight></codeline>
<codeline lineno="704"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>s<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="705"><highlight class="normal"></highlight></codeline>
<codeline lineno="706"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="707"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="708"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="709"><highlight class="normal"></highlight></codeline>
<codeline lineno="710"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;<sp/>kv_tokens;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="711"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_vec<sp/>=<sp/>k_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="712"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_vec<sp/>=<sp/>v_head<sp/>+<sp/>(size_t)j<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="713"><highlight class="normal"></highlight></codeline>
<codeline lineno="714"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="715"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="716"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>q_vec[d]<sp/>*<sp/>k_vec[d];</highlight></codeline>
<codeline lineno="717"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="718"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>score<sp/>=<sp/>dot<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="719"><highlight class="normal"></highlight></codeline>
<codeline lineno="720"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(score<sp/>&gt;<sp/>m)<sp/>{</highlight></codeline>
<codeline lineno="721"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>exp_m<sp/>=<sp/>(m<sp/>==<sp/>-INFINITY)<sp/>?<sp/>0.0f<sp/>:<sp/>expf(m<sp/>-<sp/>score);</highlight></codeline>
<codeline lineno="722"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>*=<sp/>exp_m;</highlight></codeline>
<codeline lineno="723"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="724"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>*=<sp/>exp_m;</highlight></codeline>
<codeline lineno="725"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="726"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>1.0f;</highlight></codeline>
<codeline lineno="727"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="728"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>+=<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="729"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="730"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m<sp/>=<sp/>score;</highlight></codeline>
<codeline lineno="731"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="732"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>e<sp/>=<sp/>expf(score<sp/>-<sp/>m);</highlight></codeline>
<codeline lineno="733"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>s<sp/>+=<sp/>e;</highlight></codeline>
<codeline lineno="734"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="735"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>+=<sp/>e<sp/>*<sp/>v_vec[d];</highlight></codeline>
<codeline lineno="736"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="737"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="738"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="739"><highlight class="normal"></highlight></codeline>
<codeline lineno="740"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>inv_s<sp/>=<sp/>1.0f<sp/>/<sp/>s;</highlight></codeline>
<codeline lineno="741"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>0;<sp/>d<sp/>&lt;<sp/>head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="742"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>*=<sp/>inv_s;</highlight></codeline>
<codeline lineno="743"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="744"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>d<sp/>=<sp/>head_dim;<sp/>d<sp/>&lt;<sp/>aligned_head_dim;<sp/>++d)<sp/>{</highlight></codeline>
<codeline lineno="745"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>out_vec[d]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="746"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="747"><highlight class="normal">}</highlight></codeline>
<codeline lineno="748"><highlight class="normal"></highlight></codeline>
<codeline lineno="749" refid="ckernel__engine_8h_1aac305a28084fe73b2264ae57613ba3ea" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1aac305a28084fe73b2264ae57613ba3ea" kindref="member">attention_forward_causal_head_major_gqa_flash</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q,</highlight></codeline>
<codeline lineno="750"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k,</highlight></codeline>
<codeline lineno="751"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,</highlight></codeline>
<codeline lineno="752"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*output,</highlight></codeline>
<codeline lineno="753"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="754"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="755"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="756"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="757"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim)</highlight></codeline>
<codeline lineno="758"><highlight class="normal">{</highlight></codeline>
<codeline lineno="759"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!q<sp/>||<sp/>!k<sp/>||<sp/>!v<sp/>||<sp/>!output)<sp/>{</highlight></codeline>
<codeline lineno="760"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="761"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="762"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(num_heads<sp/>&lt;=<sp/>0<sp/>||<sp/>num_kv_heads<sp/>&lt;=<sp/>0<sp/>||<sp/>num_tokens<sp/>&lt;=<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="763"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="764"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="765"><highlight class="normal"></highlight></codeline>
<codeline lineno="766"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>1.0f<sp/>/<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)head_dim);</highlight></codeline>
<codeline lineno="767"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>T<sp/>=<sp/>num_tokens;</highlight></codeline>
<codeline lineno="768"><highlight class="normal"></highlight></codeline>
<codeline lineno="769"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Select<sp/>SIMD<sp/>implementation<sp/>based<sp/>on<sp/>compile-time<sp/>CPU<sp/>features</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="770"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="771"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL<sp/>attention_flash_query_causal_avx512</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="772"><highlight class="normal"></highlight><highlight class="preprocessor">#elif<sp/>defined(__AVX2__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="773"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL<sp/>attention_flash_query_causal_avx2</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="774"><highlight class="normal"></highlight><highlight class="preprocessor">#elif<sp/>defined(__AVX__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="775"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL<sp/>attention_flash_query_causal_avx</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="776"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="777"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL<sp/>attention_flash_query_causal</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="778"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="779"><highlight class="normal"></highlight></codeline>
<codeline lineno="780"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="781"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_head<sp/>=<sp/>(int)((</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/>long)num_kv_heads<sp/>/<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)num_heads);</highlight></codeline>
<codeline lineno="782"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_head<sp/>=<sp/>k<sp/>+<sp/>(size_t)kv_head<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)T<sp/>*<sp/>(size_t)aligned_head_dim;</highlight></codeline>
<codeline lineno="783"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_head<sp/>=<sp/>v<sp/>+<sp/>(size_t)kv_head<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)T<sp/>*<sp/>(size_t)aligned_head_dim;</highlight></codeline>
<codeline lineno="784"><highlight class="normal"></highlight></codeline>
<codeline lineno="785"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>T;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="786"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_vec<sp/>=<sp/>q<sp/>+<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>T,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="787"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out_vec<sp/>=<sp/>output<sp/>+<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>T,<sp/>aligned_head_dim);</highlight></codeline>
<codeline lineno="788"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><ref refid="attention__kernels_8c_1a686599872afcb86c5fc7ad5e5e5b4773" kindref="member">FLASH_QUERY_IMPL</ref>(q_vec,<sp/>k_head,<sp/>v_head,</highlight></codeline>
<codeline lineno="789"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*kv_tokens=*/</highlight><highlight class="normal">i<sp/>+<sp/>1,</highlight></codeline>
<codeline lineno="790"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>head_dim,<sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="791"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scale,<sp/>out_vec);</highlight></codeline>
<codeline lineno="792"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="793"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="794"><highlight class="normal"></highlight></codeline>
<codeline lineno="795"><highlight class="normal"></highlight><highlight class="preprocessor">#undef<sp/>FLASH_QUERY_IMPL</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="796"><highlight class="normal">}</highlight></codeline>
<codeline lineno="797"><highlight class="normal"></highlight></codeline>
<codeline lineno="798" refid="ckernel__engine_8h_1a84803f8c5509c325dd6b9feec50a0493" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a84803f8c5509c325dd6b9feec50a0493" kindref="member">attention_forward_decode_head_major_gqa_flash</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_token,</highlight></codeline>
<codeline lineno="799"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_cache,</highlight></codeline>
<codeline lineno="800"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_cache,</highlight></codeline>
<codeline lineno="801"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out_token,</highlight></codeline>
<codeline lineno="802"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="803"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="804"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_tokens,</highlight></codeline>
<codeline lineno="805"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>cache_capacity,</highlight></codeline>
<codeline lineno="806"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="807"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim)</highlight></codeline>
<codeline lineno="808"><highlight class="normal">{</highlight></codeline>
<codeline lineno="809"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!q_token<sp/>||<sp/>!k_cache<sp/>||<sp/>!v_cache<sp/>||<sp/>!out_token)<sp/>{</highlight></codeline>
<codeline lineno="810"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="811"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="812"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(num_heads<sp/>&lt;=<sp/>0<sp/>||<sp/>num_kv_heads<sp/>&lt;=<sp/>0<sp/>||<sp/>kv_tokens<sp/>&lt;=<sp/>0<sp/>||<sp/>cache_capacity<sp/>&lt;=<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="813"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="814"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="815"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(kv_tokens<sp/>&gt;<sp/>cache_capacity)<sp/>{</highlight></codeline>
<codeline lineno="816"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="817"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="818"><highlight class="normal"></highlight></codeline>
<codeline lineno="819"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>1.0f<sp/>/<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)head_dim);</highlight></codeline>
<codeline lineno="820"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>head_stride<sp/>=<sp/>(size_t)cache_capacity<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="821"><highlight class="normal"></highlight></codeline>
<codeline lineno="822"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Select<sp/>SIMD<sp/>implementation<sp/>based<sp/>on<sp/>compile-time<sp/>CPU<sp/>features</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="823"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="824"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL_DECODE<sp/>attention_flash_query_causal_avx512</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="825"><highlight class="normal"></highlight><highlight class="preprocessor">#elif<sp/>defined(__AVX2__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="826"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL_DECODE<sp/>attention_flash_query_causal_avx2</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="827"><highlight class="normal"></highlight><highlight class="preprocessor">#elif<sp/>defined(__AVX__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="828"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL_DECODE<sp/>attention_flash_query_causal_avx</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="829"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="830"><highlight class="normal"></highlight><highlight class="preprocessor"><sp/><sp/><sp/><sp/>#define<sp/>FLASH_QUERY_IMPL_DECODE<sp/>attention_flash_query_causal</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="831"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="832"><highlight class="normal"></highlight></codeline>
<codeline lineno="833"><highlight class="normal"></highlight><highlight class="preprocessor">#pragma<sp/>omp<sp/>parallel<sp/>for<sp/>schedule(static)<sp/>if(num_heads<sp/>&gt;<sp/>1)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="834"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>num_heads;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="835"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_head<sp/>=<sp/>(int)((</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/>long)num_kv_heads<sp/>/<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)num_heads);</highlight></codeline>
<codeline lineno="836"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_vec<sp/>=<sp/>q_token<sp/>+<sp/>(size_t)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="837"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_head<sp/>=<sp/>k_cache<sp/>+<sp/>(size_t)kv_head<sp/>*<sp/>head_stride;</highlight></codeline>
<codeline lineno="838"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_head<sp/>=<sp/>v_cache<sp/>+<sp/>(size_t)kv_head<sp/>*<sp/>head_stride;</highlight></codeline>
<codeline lineno="839"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*out_vec<sp/>=<sp/>out_token<sp/>+<sp/>(size_t)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)aligned_head_dim;</highlight></codeline>
<codeline lineno="840"><highlight class="normal"></highlight></codeline>
<codeline lineno="841"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><ref refid="attention__kernels_8c_1aba8a26d95a9c96411b5fea006f2097e4" kindref="member">FLASH_QUERY_IMPL_DECODE</ref>(q_vec,<sp/>k_head,<sp/>v_head,</highlight></codeline>
<codeline lineno="842"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>kv_tokens,<sp/>head_dim,<sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="843"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>scale,<sp/>out_vec);</highlight></codeline>
<codeline lineno="844"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="845"><highlight class="normal"></highlight></codeline>
<codeline lineno="846"><highlight class="normal"></highlight><highlight class="preprocessor">#undef<sp/>FLASH_QUERY_IMPL_DECODE</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="847"><highlight class="normal">}</highlight></codeline>
<codeline lineno="848"><highlight class="normal"></highlight></codeline>
<codeline lineno="849"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="850"><highlight class="normal"></highlight><highlight class="comment">//<sp/>ATTENTION<sp/>BACKWARD<sp/>-<sp/>Causal,<sp/>Head-Major,<sp/>GQA-aware</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="851"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="852"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="853"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Backward<sp/>pass<sp/>for<sp/>scaled<sp/>dot-product<sp/>attention<sp/>with<sp/>causal<sp/>mask.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="854"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="855"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Given:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="856"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>d_output:<sp/>gradient<sp/>from<sp/>the<sp/>layer<sp/>above<sp/>[num_heads,<sp/>T,<sp/>head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="857"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>q,<sp/>k,<sp/>v:<sp/>saved<sp/>activations<sp/>from<sp/>forward<sp/>pass</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="858"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>attn_weights:<sp/>saved<sp/>softmax<sp/>output<sp/>from<sp/>forward<sp/>[num_heads,<sp/>T,<sp/>T]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="859"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="860"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Computes:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="861"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>d_q:<sp/>gradient<sp/>w.r.t.<sp/>queries<sp/><sp/>[num_heads,<sp/>T,<sp/>head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="862"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>d_k:<sp/>gradient<sp/>w.r.t.<sp/>keys<sp/><sp/><sp/><sp/><sp/>[num_kv_heads,<sp/>T,<sp/>head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="863"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>d_v:<sp/>gradient<sp/>w.r.t.<sp/>values<sp/><sp/><sp/>[num_kv_heads,<sp/>T,<sp/>head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="864"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="865"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Math<sp/>derivation:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="866"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Forward:<sp/>scores<sp/>=<sp/>Q<sp/>@<sp/>K^T<sp/>/<sp/>sqrt(d)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="867"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weights<sp/>=<sp/>causal_softmax(scores)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="868"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output<sp/>=<sp/>weights<sp/>@<sp/>V</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="869"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="870"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Backward<sp/>through<sp/>V<sp/>multiply:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="871"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/>d_weights<sp/>=<sp/>d_output<sp/>@<sp/>V^T<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[H,<sp/>T,<sp/>T]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="872"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/>d_v<sp/>=<sp/>weights^T<sp/>@<sp/>d_output<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[H_kv,<sp/>T,<sp/>d]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="873"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="874"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Backward<sp/>through<sp/>softmax:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="875"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/>d_scores<sp/>=<sp/>softmax_backward(d_weights,<sp/>weights)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="876"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="877"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Backward<sp/>through<sp/>Q<sp/>@<sp/>K^T:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="878"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/>d_q<sp/>=<sp/>d_scores<sp/>@<sp/>K<sp/>/<sp/>sqrt(d)<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>[H,<sp/>T,<sp/>d]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="879"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/>d_k<sp/>=<sp/>d_scores^T<sp/>@<sp/>Q<sp/>/<sp/>sqrt(d)<sp/><sp/><sp/><sp/><sp/><sp/><sp/>[H_kv,<sp/>T,<sp/>d]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="880"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="881"><highlight class="normal"></highlight><highlight class="comment">//<sp/>For<sp/>GQA:<sp/>multiple<sp/>query<sp/>heads<sp/>share<sp/>the<sp/>same<sp/>KV<sp/>head,<sp/>so<sp/>we<sp/>accumulate</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="882"><highlight class="normal"></highlight><highlight class="comment">//<sp/>gradients<sp/>from<sp/>all<sp/>query<sp/>heads<sp/>that<sp/>map<sp/>to<sp/>each<sp/>KV<sp/>head.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="883"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="884" refid="ckernel__engine_8h_1a1a95c2e93bfbe603df487d0c0eb5ea2b" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1a1a95c2e93bfbe603df487d0c0eb5ea2b" kindref="member">attention_backward_causal_head_major_gqa_bf16</ref>(</highlight></codeline>
<codeline lineno="885"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*d_output,<sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="886"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_x,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="887"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*q,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="888"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*k,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="889"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*v,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="890"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*attn_weights,<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_context_window]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="891"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_q,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_head_dim]<sp/>output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="892"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_k,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]<sp/>output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="893"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_v,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]<sp/>output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="894"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_scores,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_context_window]<sp/>scratch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="895"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="896"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="897"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="898"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="899"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="900"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="901"><highlight class="normal">{</highlight></codeline>
<codeline lineno="902"><highlight class="normal"><sp/><sp/><sp/><sp/>(void)d_x;</highlight></codeline>
<codeline lineno="903"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>head_elems<sp/>=<sp/>(size_t)num_heads<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)num_tokens<sp/>*<sp/>(size_t)aligned_head_dim;</highlight></codeline>
<codeline lineno="904"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>kv_elems<sp/>=<sp/>(size_t)num_kv_heads<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)num_tokens<sp/>*<sp/>(size_t)aligned_head_dim;</highlight></codeline>
<codeline lineno="905"><highlight class="normal"></highlight></codeline>
<codeline lineno="906"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_output_f<sp/>=<sp/><ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(d_output,<sp/>head_elems);</highlight></codeline>
<codeline lineno="907"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!d_output_f)<sp/>{</highlight></codeline>
<codeline lineno="908"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="909"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="910"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q_f<sp/>=<sp/><ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(q,<sp/>head_elems);</highlight></codeline>
<codeline lineno="911"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!q_f)<sp/>{</highlight></codeline>
<codeline lineno="912"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(d_output_f);</highlight></codeline>
<codeline lineno="913"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="914"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="915"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k_f<sp/>=<sp/><ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(k,<sp/>kv_elems);</highlight></codeline>
<codeline lineno="916"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!k_f)<sp/>{</highlight></codeline>
<codeline lineno="917"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(d_output_f);</highlight></codeline>
<codeline lineno="918"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(q_f);</highlight></codeline>
<codeline lineno="919"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="920"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="921"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v_f<sp/>=<sp/><ref refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" kindref="member">convert_bf16_tensor</ref>(v,<sp/>kv_elems);</highlight></codeline>
<codeline lineno="922"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!v_f)<sp/>{</highlight></codeline>
<codeline lineno="923"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(d_output_f);</highlight></codeline>
<codeline lineno="924"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(q_f);</highlight></codeline>
<codeline lineno="925"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>free(k_f);</highlight></codeline>
<codeline lineno="926"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="927"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="928"><highlight class="normal"></highlight></codeline>
<codeline lineno="929"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="attention__kernels_8c_1adbd2b55fbc53b6e288c98813b61cd6e3" kindref="member">attention_backward_causal_head_major_gqa</ref>(d_output_f,<sp/>q_f,<sp/>k_f,<sp/>v_f,</highlight></codeline>
<codeline lineno="930"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>attn_weights,</highlight></codeline>
<codeline lineno="931"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_q,<sp/>d_k,<sp/>d_v,<sp/>d_scores,</highlight></codeline>
<codeline lineno="932"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_heads,<sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="933"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_tokens,<sp/>head_dim,</highlight></codeline>
<codeline lineno="934"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>aligned_head_dim,<sp/>aligned_context_window);</highlight></codeline>
<codeline lineno="935"><highlight class="normal"></highlight></codeline>
<codeline lineno="936"><highlight class="normal"><sp/><sp/><sp/><sp/>free(d_output_f);</highlight></codeline>
<codeline lineno="937"><highlight class="normal"><sp/><sp/><sp/><sp/>free(q_f);</highlight></codeline>
<codeline lineno="938"><highlight class="normal"><sp/><sp/><sp/><sp/>free(k_f);</highlight></codeline>
<codeline lineno="939"><highlight class="normal"><sp/><sp/><sp/><sp/>free(v_f);</highlight></codeline>
<codeline lineno="940"><highlight class="normal">}</highlight></codeline>
<codeline lineno="941"><highlight class="normal"></highlight></codeline>
<codeline lineno="942" refid="ckernel__engine_8h_1adbd2b55fbc53b6e288c98813b61cd6e3" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1adbd2b55fbc53b6e288c98813b61cd6e3" kindref="member">attention_backward_causal_head_major_gqa</ref>(</highlight></codeline>
<codeline lineno="943"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_output,<sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="944"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="945"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="946"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="947"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*attn_weights,<sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_context_window]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="948"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_q,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_head_dim]<sp/>output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="949"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_k,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]<sp/>output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="950"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_v,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_kv_heads,<sp/>T,<sp/>aligned_head_dim]<sp/>output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="951"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_scores,<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>[num_heads,<sp/>T,<sp/>aligned_context_window]<sp/>scratch</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="952"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="953"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_kv_heads,</highlight></codeline>
<codeline lineno="954"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="955"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="956"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="957"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="958"><highlight class="normal">{</highlight></codeline>
<codeline lineno="959"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>1.0f<sp/>/<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)head_dim);</highlight></codeline>
<codeline lineno="960"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>T<sp/>=<sp/>num_tokens;</highlight></codeline>
<codeline lineno="961"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>H<sp/>=<sp/>num_heads;</highlight></codeline>
<codeline lineno="962"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>H_kv<sp/>=<sp/>num_kv_heads;</highlight></codeline>
<codeline lineno="963"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>hd<sp/>=<sp/>head_dim;</highlight></codeline>
<codeline lineno="964"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>ad<sp/>=<sp/>aligned_head_dim;</highlight></codeline>
<codeline lineno="965"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aw<sp/>=<sp/>aligned_context_window;</highlight></codeline>
<codeline lineno="966"><highlight class="normal"></highlight></codeline>
<codeline lineno="967"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d_q_elems<sp/>=<sp/>(size_t)H<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)T<sp/>*<sp/>(size_t)ad;</highlight></codeline>
<codeline lineno="968"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>kv_elems<sp/>=<sp/>(size_t)H_kv<sp/>*<sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal">)T<sp/>*<sp/>(size_t)ad;</highlight></codeline>
<codeline lineno="969"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*<sp/>Zero<sp/>the<sp/>aligned<sp/>outputs<sp/>so<sp/>padded<sp/>lanes<sp/>never<sp/>leak<sp/>garbage<sp/>to<sp/>downstream<sp/>GEMMs.<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="970"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>idx<sp/>=<sp/>0;<sp/>idx<sp/>&lt;<sp/>d_q_elems;<sp/>++idx)<sp/>{</highlight></codeline>
<codeline lineno="971"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_q[idx]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="972"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="973"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>idx<sp/>=<sp/>0;<sp/>idx<sp/>&lt;<sp/>kv_elems;<sp/>++idx)<sp/>{</highlight></codeline>
<codeline lineno="974"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_k[idx]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="975"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_v[idx]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="976"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="977"><highlight class="normal"></highlight></codeline>
<codeline lineno="978"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Process<sp/>each<sp/>query<sp/>head</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="979"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>h<sp/>=<sp/>0;<sp/>h<sp/>&lt;<sp/>H;<sp/>++h)<sp/>{</highlight></codeline>
<codeline lineno="980"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Which<sp/>KV<sp/>head<sp/>does<sp/>this<sp/>query<sp/>head<sp/>use?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="981"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>kv_h<sp/>=<sp/>(int)((</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)h<sp/>*<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/>long)H_kv<sp/>/<sp/>(</highlight><highlight class="keywordtype">long</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">long</highlight><highlight class="normal">)H);</highlight></codeline>
<codeline lineno="982"><highlight class="normal"></highlight></codeline>
<codeline lineno="983"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>----------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="984"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Step<sp/>1:<sp/>d_weights<sp/>=<sp/>d_output<sp/>@<sp/>V^T<sp/><sp/>and<sp/><sp/>d_v<sp/>+=<sp/>weights^T<sp/>@<sp/>d_output</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="985"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>----------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="986"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>For<sp/>each<sp/>query<sp/>position<sp/>i,<sp/>compute<sp/>d_weights[i,<sp/>j]<sp/>for<sp/>j<sp/>&lt;=<sp/>i</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="987"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>and<sp/>accumulate<sp/>d_v[j]<sp/>contributions</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="988"><highlight class="normal"></highlight></codeline>
<codeline lineno="989"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>T;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="990"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d_out_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>T,<sp/>ad);</highlight></codeline>
<codeline lineno="991"><highlight class="normal"></highlight></codeline>
<codeline lineno="992"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="993"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>v_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(kv_h,<sp/>j,<sp/>0,<sp/>T,<sp/>ad);</highlight></codeline>
<codeline lineno="994"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>w_idx<sp/>=<sp/><ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aw);</highlight></codeline>
<codeline lineno="995"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/>attn_weights[w_idx];</highlight></codeline>
<codeline lineno="996"><highlight class="normal"></highlight></codeline>
<codeline lineno="997"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>d_weights[h,<sp/>i,<sp/>j]<sp/>=<sp/>d_output[h,<sp/>i,<sp/>:]<sp/>@<sp/>v[kv_h,<sp/>j,<sp/>:]^T</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="998"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="999"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>dd<sp/>=<sp/>0;<sp/>dd<sp/>&lt;<sp/>hd;<sp/>++dd)<sp/>{</highlight></codeline>
<codeline lineno="1000"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot<sp/>+=<sp/>d_output[d_out_base<sp/>+<sp/>dd]<sp/>*<sp/>v[v_base<sp/>+<sp/>dd];</highlight></codeline>
<codeline lineno="1001"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1002"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_scores[w_idx]<sp/>=<sp/>dot;</highlight></codeline>
<codeline lineno="1003"><highlight class="normal"></highlight></codeline>
<codeline lineno="1004"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>d_v[kv_h,<sp/>j,<sp/>:]<sp/>+=<sp/>weights[h,<sp/>i,<sp/>j]<sp/>*<sp/>d_output[h,<sp/>i,<sp/>:]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1005"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>dd<sp/>=<sp/>0;<sp/>dd<sp/>&lt;<sp/>hd;<sp/>++dd)<sp/>{</highlight></codeline>
<codeline lineno="1006"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_v[v_base<sp/>+<sp/>dd]<sp/>+=<sp/>w<sp/>*<sp/>d_output[d_out_base<sp/>+<sp/>dd];</highlight></codeline>
<codeline lineno="1007"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1008"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1009"><highlight class="normal"></highlight></codeline>
<codeline lineno="1010"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero<sp/>out<sp/>upper<sp/>triangle<sp/>of<sp/>d_scores</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1011"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>i<sp/>+<sp/>1;<sp/>j<sp/>&lt;<sp/>T;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="1012"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aw)]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="1013"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1014"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">/*<sp/>Scores<sp/>scratch<sp/>uses<sp/>aligned_context_window,<sp/>zero<sp/>the<sp/>padded<sp/>columns.<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1015"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>T;<sp/>j<sp/>&lt;<sp/>aw;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="1016"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aw)]<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="1017"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1018"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1019"><highlight class="normal"></highlight></codeline>
<codeline lineno="1020"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>----------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1021"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Step<sp/>2:<sp/>Backward<sp/>through<sp/>softmax<sp/>(in-place<sp/>on<sp/>d_scores<sp/>for<sp/>this<sp/>head)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1022"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>----------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1023"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>d_scores<sp/>=<sp/>softmax_backward(d_scores,<sp/>attn_weights)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1024"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Formula:<sp/>d_score[i,j]<sp/>=<sp/>w[i,j]<sp/>*<sp/>(d_w[i,j]<sp/>-<sp/>sum_k(w[i,k]<sp/>*<sp/>d_w[i,k]))</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1025"><highlight class="normal"></highlight></codeline>
<codeline lineno="1026"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>T;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="1027"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>base<sp/>=<sp/>h<sp/>*<sp/>aw<sp/>*<sp/>aw<sp/>+<sp/>i<sp/>*<sp/>aw;</highlight></codeline>
<codeline lineno="1028"><highlight class="normal"></highlight></codeline>
<codeline lineno="1029"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Compute<sp/>dot<sp/>product:<sp/>sum_j<sp/>w[i,j]<sp/>*<sp/>d_w[i,j]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1030"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dot_product<sp/>=<sp/>0.0f;</highlight></codeline>
<codeline lineno="1031"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="1032"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>wt<sp/>=<sp/>attn_weights[base<sp/>+<sp/>j];</highlight></codeline>
<codeline lineno="1033"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dw<sp/>=<sp/>d_scores[base<sp/>+<sp/>j];</highlight></codeline>
<codeline lineno="1034"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dot_product<sp/>+=<sp/>wt<sp/>*<sp/>dw;</highlight></codeline>
<codeline lineno="1035"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1036"><highlight class="normal"></highlight></codeline>
<codeline lineno="1037"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Apply<sp/>softmax<sp/>backward<sp/>formula</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1038"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="1039"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>wt<sp/>=<sp/>attn_weights[base<sp/>+<sp/>j];</highlight></codeline>
<codeline lineno="1040"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>dw<sp/>=<sp/>d_scores[base<sp/>+<sp/>j];</highlight></codeline>
<codeline lineno="1041"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_scores[base<sp/>+<sp/>j]<sp/>=<sp/>wt<sp/>*<sp/>(dw<sp/>-<sp/>dot_product);</highlight></codeline>
<codeline lineno="1042"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1043"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1044"><highlight class="normal"></highlight></codeline>
<codeline lineno="1045"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>----------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1046"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Step<sp/>3:<sp/>d_q<sp/>=<sp/>d_scores<sp/>@<sp/>K<sp/>*<sp/>scale</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1047"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_k<sp/>+=<sp/>d_scores^T<sp/>@<sp/>Q<sp/>*<sp/>scale</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1048"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>----------------------------------------------------------------</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1049"><highlight class="normal"></highlight></codeline>
<codeline lineno="1050"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>T;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="1051"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d_q_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>T,<sp/>ad);</highlight></codeline>
<codeline lineno="1052"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>q_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(h,<sp/>i,<sp/>0,<sp/>T,<sp/>ad);</highlight></codeline>
<codeline lineno="1053"><highlight class="normal"></highlight></codeline>
<codeline lineno="1054"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>d_q[h,<sp/>i,<sp/>:]<sp/>=<sp/>sum_j<sp/>d_scores[h,<sp/>i,<sp/>j]<sp/>*<sp/>k[kv_h,<sp/>j,<sp/>:]<sp/>*<sp/>scale</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1055"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>d_k[kv_h,<sp/>j,<sp/>:]<sp/>+=<sp/>d_scores[h,<sp/>i,<sp/>j]<sp/>*<sp/>q[h,<sp/>i,<sp/>:]<sp/>*<sp/>scale</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1056"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>j<sp/>=<sp/>0;<sp/>j<sp/>&lt;=<sp/>i;<sp/>++j)<sp/>{</highlight></codeline>
<codeline lineno="1057"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>k_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(kv_h,<sp/>j,<sp/>0,<sp/>T,<sp/>ad);</highlight></codeline>
<codeline lineno="1058"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>d_k_base<sp/>=<sp/><ref refid="attention__kernels_8c_1a0102833b3c8a1d4114e65c0638ddbfb1" kindref="member">qkv_index</ref>(kv_h,<sp/>j,<sp/>0,<sp/>T,<sp/>ad);</highlight></codeline>
<codeline lineno="1059"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>ds<sp/>=<sp/>d_scores[<ref refid="attention__kernels_8c_1a730fa391639fb17027ee898e26e5db06" kindref="member">score_index</ref>(h,<sp/>i,<sp/>j,<sp/>aw)]<sp/>*<sp/>scale;</highlight></codeline>
<codeline lineno="1060"><highlight class="normal"></highlight></codeline>
<codeline lineno="1061"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>dd<sp/>=<sp/>0;<sp/>dd<sp/>&lt;<sp/>hd;<sp/>++dd)<sp/>{</highlight></codeline>
<codeline lineno="1062"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_q[d_q_base<sp/>+<sp/>dd]<sp/>+=<sp/>ds<sp/>*<sp/>k[k_base<sp/>+<sp/>dd];</highlight></codeline>
<codeline lineno="1063"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_k[d_k_base<sp/>+<sp/>dd]<sp/>+=<sp/>ds<sp/>*<sp/>q[q_base<sp/>+<sp/>dd];</highlight></codeline>
<codeline lineno="1064"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1065"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1066"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1067"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1068"><highlight class="normal">}</highlight></codeline>
<codeline lineno="1069"><highlight class="normal"></highlight></codeline>
<codeline lineno="1070"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Non-GQA<sp/>version<sp/>(num_heads<sp/>==<sp/>num_kv_heads)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1071" refid="ckernel__engine_8h_1ad611fd5e8dba3e906482d6e68f919788" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="attention__kernels_8c_1ad611fd5e8dba3e906482d6e68f919788" kindref="member">attention_backward_causal_head_major</ref>(</highlight></codeline>
<codeline lineno="1072"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_output,</highlight></codeline>
<codeline lineno="1073"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*q,</highlight></codeline>
<codeline lineno="1074"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*k,</highlight></codeline>
<codeline lineno="1075"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,</highlight></codeline>
<codeline lineno="1076"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*attn_weights,</highlight></codeline>
<codeline lineno="1077"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_q,</highlight></codeline>
<codeline lineno="1078"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_k,</highlight></codeline>
<codeline lineno="1079"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_v,</highlight></codeline>
<codeline lineno="1080"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*d_scores,</highlight></codeline>
<codeline lineno="1081"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_heads,</highlight></codeline>
<codeline lineno="1082"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>num_tokens,</highlight></codeline>
<codeline lineno="1083"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>head_dim,</highlight></codeline>
<codeline lineno="1084"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_head_dim,</highlight></codeline>
<codeline lineno="1085"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>aligned_context_window)</highlight></codeline>
<codeline lineno="1086"><highlight class="normal">{</highlight></codeline>
<codeline lineno="1087"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="attention__kernels_8c_1adbd2b55fbc53b6e288c98813b61cd6e3" kindref="member">attention_backward_causal_head_major_gqa</ref>(</highlight></codeline>
<codeline lineno="1088"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_output,<sp/>q,<sp/>k,<sp/>v,<sp/>attn_weights,</highlight></codeline>
<codeline lineno="1089"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>d_q,<sp/>d_k,<sp/>d_v,<sp/>d_scores,</highlight></codeline>
<codeline lineno="1090"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_heads,<sp/>num_heads,<sp/><sp/></highlight><highlight class="comment">//<sp/>num_kv_heads<sp/>==<sp/>num_heads</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="1091"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_tokens,<sp/>head_dim,<sp/>aligned_head_dim,<sp/>aligned_context_window);</highlight></codeline>
<codeline lineno="1092"><highlight class="normal">}</highlight></codeline>
    </programlisting>
    <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/attention_kernels.c"/>
  </compounddef>
</doxygen>
