<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.1" xml:lang="en-US">
  <compounddef id="optimizer__kernels__bf16_8c" kind="file" language="C++">
    <compoundname>optimizer_kernels_bf16.c</compoundname>
    <includes local="no">math.h</includes>
    <includes local="no">stddef.h</includes>
    <includes local="no">stdint.h</includes>
    <includes local="no">stdlib.h</includes>
    <includes local="no">string.h</includes>
    <includes refid="bf16__utils_8h" local="yes">bf16_utils.h</includes>
    <incdepgraph>
      <node id="4">
        <label>stdint.h</label>
      </node>
      <node id="5">
        <label>stdlib.h</label>
      </node>
      <node id="7">
        <label>bf16_utils.h</label>
        <link refid="bf16__utils_8h"/>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
      </node>
      <node id="3">
        <label>stddef.h</label>
      </node>
      <node id="6">
        <label>string.h</label>
      </node>
      <node id="1">
        <label>optimizer_kernels_bf16.c</label>
        <link refid="optimizer__kernels__bf16_8c"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
        <childnode refid="6" relation="include">
        </childnode>
        <childnode refid="7" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>math.h</label>
      </node>
    </incdepgraph>
      <sectiondef kind="func">
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1a04594793ece43bcbd8669ff6d0e0029b" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void adamw_update_bf16</definition>
        <argsstring>(const uint16_t *grad, uint16_t *weight, float *m, float *v, size_t numel, float lr, float beta1, float beta2, float eps, float weight_decay, int step)</argsstring>
        <name>adamw_update_bf16</name>
        <param>
          <type>const uint16_t *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>uint16_t *</type>
          <declname>weight</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>m</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <param>
          <type>float</type>
          <declname>lr</declname>
        </param>
        <param>
          <type>float</type>
          <declname>beta1</declname>
        </param>
        <param>
          <type>float</type>
          <declname>beta2</declname>
        </param>
        <param>
          <type>float</type>
          <declname>eps</declname>
        </param>
        <param>
          <type>float</type>
          <declname>weight_decay</declname>
        </param>
        <param>
          <type>int</type>
          <declname>step</declname>
        </param>
        <briefdescription>
<para>AdamW optimizer update (bf16 weights/gradients, fp32 optimizer state) </para>
        </briefdescription>
        <detaileddescription>
<para>Weights and gradients are in bf16 for memory efficiency. Momentum (m) and variance (v) are in fp32 for numerical stability.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>grad</parametername>
</parameternamelist>
<parameterdescription>
<para>Gradient tensor (bf16) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>weight</parametername>
</parameternamelist>
<parameterdescription>
<para>Weight tensor to update (bf16, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>m</parametername>
</parameternamelist>
<parameterdescription>
<para>First moment buffer (fp32, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>v</parametername>
</parameternamelist>
<parameterdescription>
<para>Second moment buffer (fp32, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>numel</parametername>
</parameternamelist>
<parameterdescription>
<para>Number of elements </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>lr</parametername>
</parameternamelist>
<parameterdescription>
<para>Learning rate </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>beta1</parametername>
</parameternamelist>
<parameterdescription>
<para>First moment decay (typically 0.9) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>beta2</parametername>
</parameternamelist>
<parameterdescription>
<para>Second moment decay (typically 0.999) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>eps</parametername>
</parameternamelist>
<parameterdescription>
<para>Numerical stability constant (typically 1e-8) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>weight_decay</parametername>
</parameternamelist>
<parameterdescription>
<para>Weight decay coefficient </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>step</parametername>
</parameternamelist>
<parameterdescription>
<para>Current step number (1-indexed) </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="48" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" bodystart="48" bodyend="148"/>
        <references refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" compoundref="bf16__utils_8h" startline="38" endline="46">bf16_to_float</references>
        <references refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" compoundref="bf16__utils_8h" startline="90" endline="103">float_to_bf16</references>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1ac1a9ed01c15286fc6e3be73f96371d76" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void adamw_update_f32</definition>
        <argsstring>(const float *grad, float *weight, float *m, float *v, size_t numel, float lr, float beta1, float beta2, float eps, float weight_decay, int step)</argsstring>
        <name>adamw_update_f32</name>
        <param>
          <type>const float *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>weight</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>m</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>v</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <param>
          <type>float</type>
          <declname>lr</declname>
        </param>
        <param>
          <type>float</type>
          <declname>beta1</declname>
        </param>
        <param>
          <type>float</type>
          <declname>beta2</declname>
        </param>
        <param>
          <type>float</type>
          <declname>eps</declname>
        </param>
        <param>
          <type>float</type>
          <declname>weight_decay</declname>
        </param>
        <param>
          <type>int</type>
          <declname>step</declname>
        </param>
        <briefdescription>
<para>AdamW optimizer update (fp32 version) </para>
        </briefdescription>
        <detaileddescription>
<para>Updates weights in-place using the AdamW algorithm. Momentum (m) and variance (v) are stored in fp32 for numerical stability.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>grad</parametername>
</parameternamelist>
<parameterdescription>
<para>Gradient tensor (fp32) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>weight</parametername>
</parameternamelist>
<parameterdescription>
<para>Weight tensor to update (fp32, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>m</parametername>
</parameternamelist>
<parameterdescription>
<para>First moment (momentum) buffer (fp32, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>v</parametername>
</parameternamelist>
<parameterdescription>
<para>Second moment (variance) buffer (fp32, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>numel</parametername>
</parameternamelist>
<parameterdescription>
<para>Number of elements </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>lr</parametername>
</parameternamelist>
<parameterdescription>
<para>Learning rate </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>beta1</parametername>
</parameternamelist>
<parameterdescription>
<para>Exponential decay rate for first moment (typically 0.9) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>beta2</parametername>
</parameternamelist>
<parameterdescription>
<para>Exponential decay rate for second moment (typically 0.999) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>eps</parametername>
</parameternamelist>
<parameterdescription>
<para>Small constant for numerical stability (typically 1e-8) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>weight_decay</parametername>
</parameternamelist>
<parameterdescription>
<para>Weight decay coefficient (typically 0.01) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>step</parametername>
</parameternamelist>
<parameterdescription>
<para>Current step number (1-indexed for bias correction) </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="18" column="13" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels.c" bodystart="43" bodyend="145" declfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" declline="18" declcolumn="13"/>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1a5d7c00758ea2a984dc6610c2df452b78" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gradient_accumulate_bf16</definition>
        <argsstring>(uint16_t *dst, const uint16_t *src, size_t numel)</argsstring>
        <name>gradient_accumulate_bf16</name>
        <param>
          <type>uint16_t *</type>
          <declname>dst</declname>
        </param>
        <param>
          <type>const uint16_t *</type>
          <declname>src</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <briefdescription>
<para>Accumulate gradients: dst += src (bf16) </para>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="220" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" bodystart="220" bodyend="245"/>
        <references refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" compoundref="bf16__utils_8h" startline="38" endline="46">bf16_to_float</references>
        <references refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" compoundref="bf16__utils_8h" startline="90" endline="103">float_to_bf16</references>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1ac43e9094fbc4956d450b5f6deb5ae899" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gradient_accumulate_f32</definition>
        <argsstring>(float *dst, const float *src, size_t numel)</argsstring>
        <name>gradient_accumulate_f32</name>
        <param>
          <type>float *</type>
          <declname>dst</declname>
        </param>
        <param>
          <type>const float *</type>
          <declname>src</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <briefdescription>
<para>Accumulate gradients: dst += src (fp32) </para>
        </briefdescription>
        <detaileddescription>
<para>Used for gradient accumulation across micro-batches.</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>dst</parametername>
</parameternamelist>
<parameterdescription>
<para>Destination gradient buffer (in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>src</parametername>
</parameternamelist>
<parameterdescription>
<para>Source gradient buffer [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>numel</parametername>
</parameternamelist>
<parameterdescription>
<para>Number of elements </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="26" column="13" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels.c" bodystart="234" bodyend="255" declfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" declline="26" declcolumn="13"/>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1a3b775fa9d57eebd6e004caa317f1b9e3" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>float</type>
        <definition>float gradient_clip_norm_bf16</definition>
        <argsstring>(uint16_t *grad, size_t numel, float max_norm)</argsstring>
        <name>gradient_clip_norm_bf16</name>
        <param>
          <type>uint16_t *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <param>
          <type>float</type>
          <declname>max_norm</declname>
        </param>
        <briefdescription>
<para>Clip gradient norm (bf16) </para>
        </briefdescription>
        <detaileddescription>
<para><simplesect kind="return"><para>The original L2 norm before clipping </para>
</simplesect>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="282" column="7" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" bodystart="282" bodyend="317"/>
        <references refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" compoundref="bf16__utils_8h" startline="38" endline="46">bf16_to_float</references>
        <references refid="optimizer__kernels__bf16_8c_1a6a19ebe41c76f7394ecdc70784f0d449" compoundref="optimizer__kernels__bf16_8c" startline="251" endline="274">gradient_scale_bf16</references>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1a6a19ebe41c76f7394ecdc70784f0d449" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gradient_scale_bf16</definition>
        <argsstring>(uint16_t *grad, size_t numel, float scale)</argsstring>
        <name>gradient_scale_bf16</name>
        <param>
          <type>uint16_t *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <param>
          <type>float</type>
          <declname>scale</declname>
        </param>
        <briefdescription>
<para>Scale gradients: grad *= scale (bf16) </para>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="251" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" bodystart="251" bodyend="274"/>
        <references refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" compoundref="bf16__utils_8h" startline="38" endline="46">bf16_to_float</references>
        <references refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" compoundref="bf16__utils_8h" startline="90" endline="103">float_to_bf16</references>
        <referencedby refid="optimizer__kernels__bf16_8c_1a3b775fa9d57eebd6e004caa317f1b9e3" compoundref="optimizer__kernels__bf16_8c" startline="282" endline="317">gradient_clip_norm_bf16</referencedby>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1ab615ca5560d68ed2f098960cd81acfc2" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void gradient_scale_f32</definition>
        <argsstring>(float *grad, size_t numel, float scale)</argsstring>
        <name>gradient_scale_f32</name>
        <param>
          <type>float *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <param>
          <type>float</type>
          <declname>scale</declname>
        </param>
        <briefdescription>
<para>Scale gradients by a constant: grad *= scale (fp32) </para>
        </briefdescription>
        <detaileddescription>
<para>Used for averaging gradients after accumulation: grad /= batch_size</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>grad</parametername>
</parameternamelist>
<parameterdescription>
<para>Gradient tensor to scale (in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>numel</parametername>
</parameternamelist>
<parameterdescription>
<para>Number of elements </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>scale</parametername>
</parameternamelist>
<parameterdescription>
<para>Scale factor (typically 1.0 / batch_size) </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="27" column="13" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels.c" bodystart="267" bodyend="288" declfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" declline="27" declcolumn="13"/>
        <referencedby refid="optimizer__kernels_8c_1a4e854ffc919637e40ea0d320ecb5ed0b" compoundref="optimizer__kernels_8c" startline="301" endline="335">gradient_clip_norm_f32</referencedby>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1a83c7cc71f8975e4b7c83ac26229e203f" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void sgd_momentum_update_bf16</definition>
        <argsstring>(const uint16_t *grad, uint16_t *weight, float *velocity, size_t numel, float lr, float momentum, float weight_decay)</argsstring>
        <name>sgd_momentum_update_bf16</name>
        <param>
          <type>const uint16_t *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>uint16_t *</type>
          <declname>weight</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>velocity</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <param>
          <type>float</type>
          <declname>lr</declname>
        </param>
        <param>
          <type>float</type>
          <declname>momentum</declname>
        </param>
        <param>
          <type>float</type>
          <declname>weight_decay</declname>
        </param>
        <briefdescription>
<para>SGD with momentum (bf16 weights/gradients) </para>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="154" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" bodystart="154" bodyend="202"/>
        <references refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" compoundref="bf16__utils_8h" startline="38" endline="46">bf16_to_float</references>
        <references refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" compoundref="bf16__utils_8h" startline="90" endline="103">float_to_bf16</references>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1a1c1d97635474696da41a9f318ac7600b" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void sgd_momentum_update_f32</definition>
        <argsstring>(const float *grad, float *weight, float *velocity, size_t numel, float lr, float momentum, float weight_decay)</argsstring>
        <name>sgd_momentum_update_f32</name>
        <param>
          <type>const float *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>weight</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>velocity</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <param>
          <type>float</type>
          <declname>lr</declname>
        </param>
        <param>
          <type>float</type>
          <declname>momentum</declname>
        </param>
        <param>
          <type>float</type>
          <declname>weight_decay</declname>
        </param>
        <briefdescription>
<para>SGD with momentum optimizer update (fp32 version) </para>
        </briefdescription>
        <detaileddescription>
<para>v_t = momentum * v_{t-1} + g_t w_t = w_{t-1} - lr * (v_t + weight_decay * w_{t-1})</para>
<para><parameterlist kind="param"><parameteritem>
<parameternamelist>
<parametername>grad</parametername>
</parameternamelist>
<parameterdescription>
<para>Gradient tensor (fp32) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>weight</parametername>
</parameternamelist>
<parameterdescription>
<para>Weight tensor to update (fp32, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>velocity</parametername>
</parameternamelist>
<parameterdescription>
<para>Velocity buffer (fp32, in-place) [numel] </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>numel</parametername>
</parameternamelist>
<parameterdescription>
<para>Number of elements </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>lr</parametername>
</parameternamelist>
<parameterdescription>
<para>Learning rate </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>momentum</parametername>
</parameternamelist>
<parameterdescription>
<para>Momentum coefficient (typically 0.9) </para>
</parameterdescription>
</parameteritem>
<parameteritem>
<parameternamelist>
<parametername>weight_decay</parametername>
</parameternamelist>
<parameterdescription>
<para>Weight decay coefficient </para>
</parameterdescription>
</parameteritem>
</parameterlist>
</para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="22" column="13" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels.c" bodystart="162" bodyend="207" declfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" declline="22" declcolumn="13"/>
      </memberdef>
      <memberdef kind="function" id="optimizer__kernels__bf16_8c_1a0461e04c92bea2dfd26c2f8cff17c871" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type>void</type>
        <definition>void zero_gradients_bf16</definition>
        <argsstring>(uint16_t *grad, size_t numel)</argsstring>
        <name>zero_gradients_bf16</name>
        <param>
          <type>uint16_t *</type>
          <declname>grad</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>numel</declname>
        </param>
        <briefdescription>
<para>Zero out gradient buffer (bf16) </para>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" line="208" column="6" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c" bodystart="208" bodyend="214"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
<para>BF16 optimizer kernels for training. </para>
    </briefdescription>
    <detaileddescription>
<para>Note: Optimizer state (m, v) is always kept in fp32 for numerical stability. Only weights and gradients are in bf16. </para>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="comment">/**</highlight></codeline>
<codeline lineno="2"><highlight class="comment"><sp/>*<sp/>@file<sp/>optimizer_kernels_bf16.c</highlight></codeline>
<codeline lineno="3"><highlight class="comment"><sp/>*<sp/>@brief<sp/>BF16<sp/>optimizer<sp/>kernels<sp/>for<sp/>training</highlight></codeline>
<codeline lineno="4"><highlight class="comment"><sp/>*</highlight></codeline>
<codeline lineno="5"><highlight class="comment"><sp/>*<sp/>Note:<sp/>Optimizer<sp/>state<sp/>(m,<sp/>v)<sp/>is<sp/>always<sp/>kept<sp/>in<sp/>fp32<sp/>for<sp/>numerical<sp/>stability.</highlight></codeline>
<codeline lineno="6"><highlight class="comment"><sp/>*<sp/>Only<sp/>weights<sp/>and<sp/>gradients<sp/>are<sp/>in<sp/>bf16.</highlight></codeline>
<codeline lineno="7"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;math.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stddef.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdint.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdlib.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;string.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&quot;<ref refid="bf16__utils_8h" kindref="compound">bf16_utils.h</ref>&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="16"><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal"></highlight><highlight class="comment">/*<sp/>Forward<sp/>declarations<sp/>of<sp/>fp32<sp/>kernels<sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="18"><highlight class="normal"></highlight><highlight class="keyword">extern</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1ac1a9ed01c15286fc6e3be73f96371d76" kindref="member">adamw_update_f32</ref>(</highlight></codeline>
<codeline lineno="19"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*grad,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*weight,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*m,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel,</highlight></codeline>
<codeline lineno="20"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>beta1,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>beta2,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>weight_decay,<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>step);</highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight><highlight class="keyword">extern</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1a1c1d97635474696da41a9f318ac7600b" kindref="member">sgd_momentum_update_f32</ref>(</highlight></codeline>
<codeline lineno="23"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*grad,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*weight,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*velocity,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel,</highlight></codeline>
<codeline lineno="24"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>momentum,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>weight_decay);</highlight></codeline>
<codeline lineno="25"><highlight class="normal"></highlight></codeline>
<codeline lineno="26"><highlight class="normal"></highlight><highlight class="keyword">extern</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1ac43e9094fbc4956d450b5f6deb5ae899" kindref="member">gradient_accumulate_f32</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*dst,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*src,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel);</highlight></codeline>
<codeline lineno="27"><highlight class="normal"></highlight><highlight class="keyword">extern</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1ab615ca5560d68ed2f098960cd81acfc2" kindref="member">gradient_scale_f32</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*grad,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale);</highlight></codeline>
<codeline lineno="28"><highlight class="normal"></highlight></codeline>
<codeline lineno="29"><highlight class="normal"></highlight><highlight class="comment"></highlight></codeline>
<codeline lineno="30"><highlight class="comment">/**</highlight></codeline>
<codeline lineno="31"><highlight class="comment"><sp/>*<sp/>@brief<sp/>AdamW<sp/>optimizer<sp/>update<sp/>(bf16<sp/>weights/gradients,<sp/>fp32<sp/>optimizer<sp/>state)</highlight></codeline>
<codeline lineno="32"><highlight class="comment"><sp/>*</highlight></codeline>
<codeline lineno="33"><highlight class="comment"><sp/>*<sp/>Weights<sp/>and<sp/>gradients<sp/>are<sp/>in<sp/>bf16<sp/>for<sp/>memory<sp/>efficiency.</highlight></codeline>
<codeline lineno="34"><highlight class="comment"><sp/>*<sp/>Momentum<sp/>(m)<sp/>and<sp/>variance<sp/>(v)<sp/>are<sp/>in<sp/>fp32<sp/>for<sp/>numerical<sp/>stability.</highlight></codeline>
<codeline lineno="35"><highlight class="comment"><sp/>*</highlight></codeline>
<codeline lineno="36"><highlight class="comment"><sp/>*<sp/>@param<sp/>grad<sp/><sp/><sp/><sp/><sp/><sp/><sp/>Gradient<sp/>tensor<sp/>(bf16)<sp/>[numel]</highlight></codeline>
<codeline lineno="37"><highlight class="comment"><sp/>*<sp/>@param<sp/>weight<sp/><sp/><sp/><sp/><sp/>Weight<sp/>tensor<sp/>to<sp/>update<sp/>(bf16,<sp/>in-place)<sp/>[numel]</highlight></codeline>
<codeline lineno="38"><highlight class="comment"><sp/>*<sp/>@param<sp/>m<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>First<sp/>moment<sp/>buffer<sp/>(fp32,<sp/>in-place)<sp/>[numel]</highlight></codeline>
<codeline lineno="39"><highlight class="comment"><sp/>*<sp/>@param<sp/>v<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Second<sp/>moment<sp/>buffer<sp/>(fp32,<sp/>in-place)<sp/>[numel]</highlight></codeline>
<codeline lineno="40"><highlight class="comment"><sp/>*<sp/>@param<sp/>numel<sp/><sp/><sp/><sp/><sp/><sp/>Number<sp/>of<sp/>elements</highlight></codeline>
<codeline lineno="41"><highlight class="comment"><sp/>*<sp/>@param<sp/>lr<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Learning<sp/>rate</highlight></codeline>
<codeline lineno="42"><highlight class="comment"><sp/>*<sp/>@param<sp/>beta1<sp/><sp/><sp/><sp/><sp/><sp/>First<sp/>moment<sp/>decay<sp/>(typically<sp/>0.9)</highlight></codeline>
<codeline lineno="43"><highlight class="comment"><sp/>*<sp/>@param<sp/>beta2<sp/><sp/><sp/><sp/><sp/><sp/>Second<sp/>moment<sp/>decay<sp/>(typically<sp/>0.999)</highlight></codeline>
<codeline lineno="44"><highlight class="comment"><sp/>*<sp/>@param<sp/>eps<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Numerical<sp/>stability<sp/>constant<sp/>(typically<sp/>1e-8)</highlight></codeline>
<codeline lineno="45"><highlight class="comment"><sp/>*<sp/>@param<sp/>weight_decay<sp/>Weight<sp/>decay<sp/>coefficient</highlight></codeline>
<codeline lineno="46"><highlight class="comment"><sp/>*<sp/>@param<sp/>step<sp/><sp/><sp/><sp/><sp/><sp/><sp/>Current<sp/>step<sp/>number<sp/>(1-indexed)</highlight></codeline>
<codeline lineno="47"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="48" refid="optimizer__kernels__bf16_8c_1a04594793ece43bcbd8669ff6d0e0029b" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1a04594793ece43bcbd8669ff6d0e0029b" kindref="member">adamw_update_bf16</ref>(</highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*grad,</highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/><sp/><sp/>uint16_t<sp/>*weight,</highlight></codeline>
<codeline lineno="51"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*m,</highlight></codeline>
<codeline lineno="52"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*v,</highlight></codeline>
<codeline lineno="53"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel,</highlight></codeline>
<codeline lineno="54"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>beta1,</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>beta2,</highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>eps,</highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>weight_decay,</highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>step)</highlight></codeline>
<codeline lineno="60"><highlight class="normal">{</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!grad<sp/>||<sp/>!weight<sp/>||<sp/>!m<sp/>||<sp/>!v<sp/>||<sp/>numel<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="64"><highlight class="normal"></highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Bias<sp/>correction<sp/>terms</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>bias_correction1<sp/>=<sp/>1.0f<sp/>-<sp/>powf(beta1,<sp/>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)step);</highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>bias_correction2<sp/>=<sp/>1.0f<sp/>-<sp/>powf(beta2,<sp/>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)step);</highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>one_minus_beta1<sp/>=<sp/>1.0f<sp/>-<sp/>beta1;</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>one_minus_beta2<sp/>=<sp/>1.0f<sp/>-<sp/>beta2;</highlight></codeline>
<codeline lineno="70"><highlight class="normal"></highlight></codeline>
<codeline lineno="71"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Vectorized<sp/>path:<sp/>process<sp/>16<sp/>elements<sp/>at<sp/>a<sp/>time</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_beta1<sp/>=<sp/>_mm512_set1_ps(beta1);</highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_beta2<sp/>=<sp/>_mm512_set1_ps(beta2);</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_one_minus_beta1<sp/>=<sp/>_mm512_set1_ps(one_minus_beta1);</highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_one_minus_beta2<sp/>=<sp/>_mm512_set1_ps(one_minus_beta2);</highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_lr<sp/>=<sp/>_mm512_set1_ps(lr);</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_eps<sp/>=<sp/>_mm512_set1_ps(eps);</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_weight_decay<sp/>=<sp/>_mm512_set1_ps(weight_decay);</highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_bc1_inv<sp/>=<sp/>_mm512_set1_ps(1.0f<sp/>/<sp/>bias_correction1);</highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_bc2_inv<sp/>=<sp/>_mm512_set1_ps(1.0f<sp/>/<sp/>bias_correction2);</highlight></codeline>
<codeline lineno="82"><highlight class="normal"></highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>+<sp/>16<sp/>&lt;=<sp/>numel;<sp/>i<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Load<sp/>bf16<sp/>gradient<sp/>and<sp/>weight,<sp/>convert<sp/>to<sp/>fp32</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="86"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>g<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;grad[i]);</highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>w<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;weight[i]);</highlight></codeline>
<codeline lineno="88"><highlight class="normal"></highlight></codeline>
<codeline lineno="89"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Load<sp/>fp32<sp/>optimizer<sp/>state</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="90"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>m_val<sp/>=<sp/>_mm512_loadu_ps(&amp;m[i]);</highlight></codeline>
<codeline lineno="91"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>v_val<sp/>=<sp/>_mm512_loadu_ps(&amp;v[i]);</highlight></codeline>
<codeline lineno="92"><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Update<sp/>m:<sp/>m<sp/>=<sp/>beta1<sp/>*<sp/>m<sp/>+<sp/>(1<sp/>-<sp/>beta1)<sp/>*<sp/>g</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m_val<sp/>=<sp/>_mm512_fmadd_ps(v_beta1,<sp/>m_val,<sp/>_mm512_mul_ps(v_one_minus_beta1,<sp/>g));</highlight></codeline>
<codeline lineno="95"><highlight class="normal"></highlight></codeline>
<codeline lineno="96"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Update<sp/>v:<sp/>v<sp/>=<sp/>beta2<sp/>*<sp/>v<sp/>+<sp/>(1<sp/>-<sp/>beta2)<sp/>*<sp/>g^2</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>g_sq<sp/>=<sp/>_mm512_mul_ps(g,<sp/>g);</highlight></codeline>
<codeline lineno="98"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>v_val<sp/>=<sp/>_mm512_fmadd_ps(v_beta2,<sp/>v_val,<sp/>_mm512_mul_ps(v_one_minus_beta2,<sp/>g_sq));</highlight></codeline>
<codeline lineno="99"><highlight class="normal"></highlight></codeline>
<codeline lineno="100"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Bias-corrected<sp/>estimates</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="101"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>m_hat<sp/>=<sp/>_mm512_mul_ps(m_val,<sp/>v_bc1_inv);</highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>v_hat<sp/>=<sp/>_mm512_mul_ps(v_val,<sp/>v_bc2_inv);</highlight></codeline>
<codeline lineno="103"><highlight class="normal"></highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Update<sp/>weight:<sp/>w<sp/>=<sp/>w<sp/>-<sp/>lr<sp/>*<sp/>(m_hat<sp/>/<sp/>(sqrt(v_hat)<sp/>+<sp/>eps)<sp/>+<sp/>weight_decay<sp/>*<sp/>w)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="105"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>denom<sp/>=<sp/>_mm512_add_ps(_mm512_sqrt_ps(v_hat),<sp/>v_eps);</highlight></codeline>
<codeline lineno="106"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>update<sp/>=<sp/>_mm512_div_ps(m_hat,<sp/>denom);</highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>update<sp/>=<sp/>_mm512_fmadd_ps(v_weight_decay,<sp/>w,<sp/>update);</highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w<sp/>=<sp/>_mm512_fnmadd_ps(v_lr,<sp/>update,<sp/>w);</highlight></codeline>
<codeline lineno="109"><highlight class="normal"></highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Store<sp/>updated<sp/>weight<sp/>as<sp/>bf16</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fp32_cvt_storeu_bf16(&amp;weight[i],<sp/>w);</highlight></codeline>
<codeline lineno="112"><highlight class="normal"></highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Store<sp/>updated<sp/>optimizer<sp/>state<sp/>(stays<sp/>fp32)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;m[i],<sp/>m_val);</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;v[i],<sp/>v_val);</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="117"><highlight class="normal"></highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Scalar<sp/>tail</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="119"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(weight[i]);</highlight></codeline>
<codeline lineno="122"><highlight class="normal"></highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m[i]<sp/>=<sp/>beta1<sp/>*<sp/>m[i]<sp/>+<sp/>one_minus_beta1<sp/>*<sp/>g;</highlight></codeline>
<codeline lineno="124"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>v[i]<sp/>=<sp/>beta2<sp/>*<sp/>v[i]<sp/>+<sp/>one_minus_beta2<sp/>*<sp/>g<sp/>*<sp/>g;</highlight></codeline>
<codeline lineno="125"><highlight class="normal"></highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>m_hat<sp/>=<sp/>m[i]<sp/>/<sp/>bias_correction1;</highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>v_hat<sp/>=<sp/>v[i]<sp/>/<sp/>bias_correction2;</highlight></codeline>
<codeline lineno="128"><highlight class="normal"></highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w<sp/>=<sp/>w<sp/>-<sp/>lr<sp/>*<sp/>(m_hat<sp/>/<sp/>(sqrtf(v_hat)<sp/>+<sp/>eps)<sp/>+<sp/>weight_decay<sp/>*<sp/>w);</highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(w);</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="132"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Scalar<sp/>path</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(weight[i]);</highlight></codeline>
<codeline lineno="137"><highlight class="normal"></highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m[i]<sp/>=<sp/>beta1<sp/>*<sp/>m[i]<sp/>+<sp/>one_minus_beta1<sp/>*<sp/>g;</highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>v[i]<sp/>=<sp/>beta2<sp/>*<sp/>v[i]<sp/>+<sp/>one_minus_beta2<sp/>*<sp/>g<sp/>*<sp/>g;</highlight></codeline>
<codeline lineno="140"><highlight class="normal"></highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>m_hat<sp/>=<sp/>m[i]<sp/>/<sp/>bias_correction1;</highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>v_hat<sp/>=<sp/>v[i]<sp/>/<sp/>bias_correction2;</highlight></codeline>
<codeline lineno="143"><highlight class="normal"></highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w<sp/>=<sp/>w<sp/>-<sp/>lr<sp/>*<sp/>(m_hat<sp/>/<sp/>(sqrtf(v_hat)<sp/>+<sp/>eps)<sp/>+<sp/>weight_decay<sp/>*<sp/>w);</highlight></codeline>
<codeline lineno="145"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(w);</highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="147"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="148"><highlight class="normal">}</highlight></codeline>
<codeline lineno="149"><highlight class="normal"></highlight></codeline>
<codeline lineno="150"><highlight class="normal"></highlight><highlight class="comment"></highlight></codeline>
<codeline lineno="151"><highlight class="comment">/**</highlight></codeline>
<codeline lineno="152"><highlight class="comment"><sp/>*<sp/>@brief<sp/>SGD<sp/>with<sp/>momentum<sp/>(bf16<sp/>weights/gradients)</highlight></codeline>
<codeline lineno="153"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="154" refid="optimizer__kernels__bf16_8c_1a83c7cc71f8975e4b7c83ac26229e203f" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1a83c7cc71f8975e4b7c83ac26229e203f" kindref="member">sgd_momentum_update_bf16</ref>(</highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*grad,</highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/>uint16_t<sp/>*weight,</highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*velocity,</highlight></codeline>
<codeline lineno="158"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel,</highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>lr,</highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>momentum,</highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>weight_decay)</highlight></codeline>
<codeline lineno="162"><highlight class="normal">{</highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!grad<sp/>||<sp/>!weight<sp/>||<sp/>!velocity<sp/>||<sp/>numel<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="166"><highlight class="normal"></highlight></codeline>
<codeline lineno="167"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_lr<sp/>=<sp/>_mm512_set1_ps(lr);</highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_momentum<sp/>=<sp/>_mm512_set1_ps(momentum);</highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_weight_decay<sp/>=<sp/>_mm512_set1_ps(weight_decay);</highlight></codeline>
<codeline lineno="171"><highlight class="normal"></highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="173"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>+<sp/>16<sp/>&lt;=<sp/>numel;<sp/>i<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="174"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>g<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;grad[i]);</highlight></codeline>
<codeline lineno="175"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>w<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;weight[i]);</highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>vel<sp/>=<sp/>_mm512_loadu_ps(&amp;velocity[i]);</highlight></codeline>
<codeline lineno="177"><highlight class="normal"></highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>vel<sp/>=<sp/>_mm512_fmadd_ps(v_momentum,<sp/>vel,<sp/>g);</highlight></codeline>
<codeline lineno="179"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>update<sp/>=<sp/>_mm512_fmadd_ps(v_weight_decay,<sp/>w,<sp/>vel);</highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w<sp/>=<sp/>_mm512_fnmadd_ps(v_lr,<sp/>update,<sp/>w);</highlight></codeline>
<codeline lineno="181"><highlight class="normal"></highlight></codeline>
<codeline lineno="182"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fp32_cvt_storeu_bf16(&amp;weight[i],<sp/>w);</highlight></codeline>
<codeline lineno="183"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;velocity[i],<sp/>vel);</highlight></codeline>
<codeline lineno="184"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="185"><highlight class="normal"></highlight></codeline>
<codeline lineno="186"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="187"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="188"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(weight[i]);</highlight></codeline>
<codeline lineno="189"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>velocity[i]<sp/>=<sp/>momentum<sp/>*<sp/>velocity[i]<sp/>+<sp/>g;</highlight></codeline>
<codeline lineno="190"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w<sp/>=<sp/>w<sp/>-<sp/>lr<sp/>*<sp/>(velocity[i]<sp/>+<sp/>weight_decay<sp/>*<sp/>w);</highlight></codeline>
<codeline lineno="191"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(w);</highlight></codeline>
<codeline lineno="192"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="193"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="194"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="195"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="196"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>w<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(weight[i]);</highlight></codeline>
<codeline lineno="197"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>velocity[i]<sp/>=<sp/>momentum<sp/>*<sp/>velocity[i]<sp/>+<sp/>g;</highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>w<sp/>=<sp/>w<sp/>-<sp/>lr<sp/>*<sp/>(velocity[i]<sp/>+<sp/>weight_decay<sp/>*<sp/>w);</highlight></codeline>
<codeline lineno="199"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>weight[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(w);</highlight></codeline>
<codeline lineno="200"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="201"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="202"><highlight class="normal">}</highlight></codeline>
<codeline lineno="203"><highlight class="normal"></highlight></codeline>
<codeline lineno="204"><highlight class="normal"></highlight><highlight class="comment"></highlight></codeline>
<codeline lineno="205"><highlight class="comment">/**</highlight></codeline>
<codeline lineno="206"><highlight class="comment"><sp/>*<sp/>@brief<sp/>Zero<sp/>out<sp/>gradient<sp/>buffer<sp/>(bf16)</highlight></codeline>
<codeline lineno="207"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="208" refid="optimizer__kernels__bf16_8c_1a0461e04c92bea2dfd26c2f8cff17c871" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1a0461e04c92bea2dfd26c2f8cff17c871" kindref="member">zero_gradients_bf16</ref>(uint16_t<sp/>*grad,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel)</highlight></codeline>
<codeline lineno="209"><highlight class="normal">{</highlight></codeline>
<codeline lineno="210"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!grad<sp/>||<sp/>numel<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="211"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="212"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="213"><highlight class="normal"><sp/><sp/><sp/><sp/>memset(grad,<sp/>0,<sp/>numel<sp/>*<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(uint16_t));</highlight></codeline>
<codeline lineno="214"><highlight class="normal">}</highlight></codeline>
<codeline lineno="215"><highlight class="normal"></highlight></codeline>
<codeline lineno="216"><highlight class="normal"></highlight><highlight class="comment"></highlight></codeline>
<codeline lineno="217"><highlight class="comment">/**</highlight></codeline>
<codeline lineno="218"><highlight class="comment"><sp/>*<sp/>@brief<sp/>Accumulate<sp/>gradients:<sp/>dst<sp/>+=<sp/>src<sp/>(bf16)</highlight></codeline>
<codeline lineno="219"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="220" refid="optimizer__kernels__bf16_8c_1a5d7c00758ea2a984dc6610c2df452b78" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1a5d7c00758ea2a984dc6610c2df452b78" kindref="member">gradient_accumulate_bf16</ref>(uint16_t<sp/>*dst,<sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*src,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel)</highlight></codeline>
<codeline lineno="221"><highlight class="normal">{</highlight></codeline>
<codeline lineno="222"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!dst<sp/>||<sp/>!src<sp/>||<sp/>numel<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="223"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="224"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="225"><highlight class="normal"></highlight></codeline>
<codeline lineno="226"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="227"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="228"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>+<sp/>16<sp/>&lt;=<sp/>numel;<sp/>i<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="229"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>d<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;dst[i]);</highlight></codeline>
<codeline lineno="230"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>s<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;src[i]);</highlight></codeline>
<codeline lineno="231"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fp32_cvt_storeu_bf16(&amp;dst[i],<sp/>_mm512_add_ps(d,<sp/>s));</highlight></codeline>
<codeline lineno="232"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="234"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>d<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(dst[i]);</highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>s<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(src[i]);</highlight></codeline>
<codeline lineno="236"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dst[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(d<sp/>+<sp/>s);</highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="238"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>d<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(dst[i]);</highlight></codeline>
<codeline lineno="241"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>s<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(src[i]);</highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dst[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(d<sp/>+<sp/>s);</highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="244"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="245"><highlight class="normal">}</highlight></codeline>
<codeline lineno="246"><highlight class="normal"></highlight></codeline>
<codeline lineno="247"><highlight class="normal"></highlight><highlight class="comment"></highlight></codeline>
<codeline lineno="248"><highlight class="comment">/**</highlight></codeline>
<codeline lineno="249"><highlight class="comment"><sp/>*<sp/>@brief<sp/>Scale<sp/>gradients:<sp/>grad<sp/>*=<sp/>scale<sp/>(bf16)</highlight></codeline>
<codeline lineno="250"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="251" refid="optimizer__kernels__bf16_8c_1a6a19ebe41c76f7394ecdc70784f0d449" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1a6a19ebe41c76f7394ecdc70784f0d449" kindref="member">gradient_scale_bf16</ref>(uint16_t<sp/>*grad,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale)</highlight></codeline>
<codeline lineno="252"><highlight class="normal">{</highlight></codeline>
<codeline lineno="253"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!grad<sp/>||<sp/>numel<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline lineno="254"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="255"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="256"><highlight class="normal"></highlight></codeline>
<codeline lineno="257"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="258"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>v_scale<sp/>=<sp/>_mm512_set1_ps(scale);</highlight></codeline>
<codeline lineno="259"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="260"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>+<sp/>16<sp/>&lt;=<sp/>numel;<sp/>i<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="261"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>g<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;grad[i]);</highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fp32_cvt_storeu_bf16(&amp;grad[i],<sp/>_mm512_mul_ps(g,<sp/>v_scale));</highlight></codeline>
<codeline lineno="263"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="266"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>grad[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(g<sp/>*<sp/>scale);</highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="268"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="269"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="270"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="271"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>grad[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(g<sp/>*<sp/>scale);</highlight></codeline>
<codeline lineno="272"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="273"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="274"><highlight class="normal">}</highlight></codeline>
<codeline lineno="275"><highlight class="normal"></highlight></codeline>
<codeline lineno="276"><highlight class="normal"></highlight><highlight class="comment"></highlight></codeline>
<codeline lineno="277"><highlight class="comment">/**</highlight></codeline>
<codeline lineno="278"><highlight class="comment"><sp/>*<sp/>@brief<sp/>Clip<sp/>gradient<sp/>norm<sp/>(bf16)</highlight></codeline>
<codeline lineno="279"><highlight class="comment"><sp/>*</highlight></codeline>
<codeline lineno="280"><highlight class="comment"><sp/>*<sp/>@return<sp/>The<sp/>original<sp/>L2<sp/>norm<sp/>before<sp/>clipping</highlight></codeline>
<codeline lineno="281"><highlight class="comment"><sp/>*/</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="282" refid="optimizer__kernels__bf16_8c_1a3b775fa9d57eebd6e004caa317f1b9e3" refkind="member"><highlight class="normal"></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><ref refid="optimizer__kernels__bf16_8c_1a3b775fa9d57eebd6e004caa317f1b9e3" kindref="member">gradient_clip_norm_bf16</ref>(uint16_t<sp/>*grad,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>numel,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>max_norm)</highlight></codeline>
<codeline lineno="283"><highlight class="normal">{</highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!grad<sp/>||<sp/>numel<sp/>==<sp/>0<sp/>||<sp/>max_norm<sp/>&lt;=<sp/>0.0f)<sp/>{</highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>0.0f;</highlight></codeline>
<codeline lineno="286"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="287"><highlight class="normal"></highlight></codeline>
<codeline lineno="288"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Compute<sp/>L2<sp/>norm<sp/>in<sp/>fp32<sp/>for<sp/>accuracy</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>sum_sq<sp/>=<sp/>0.0;</highlight></codeline>
<codeline lineno="290"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512<sp/>acc<sp/>=<sp/>_mm512_setzero_ps();</highlight></codeline>
<codeline lineno="292"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>+<sp/>16<sp/>&lt;=<sp/>numel;<sp/>i<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>g<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;grad[i]);</highlight></codeline>
<codeline lineno="295"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>acc<sp/>=<sp/>_mm512_fmadd_ps(g,<sp/>g,<sp/>acc);</highlight></codeline>
<codeline lineno="296"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="297"><highlight class="normal"><sp/><sp/><sp/><sp/>sum_sq<sp/>=<sp/>_mm512_reduce_add_ps(acc);</highlight></codeline>
<codeline lineno="298"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="299"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="300"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>sum_sq<sp/>+=<sp/>(double)g<sp/>*<sp/>(</highlight><highlight class="keywordtype">double</highlight><highlight class="normal">)g;</highlight></codeline>
<codeline lineno="301"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="302"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="303"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>numel;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="304"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>g<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(grad[i]);</highlight></codeline>
<codeline lineno="305"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>sum_sq<sp/>+=<sp/>(double)g<sp/>*<sp/>(</highlight><highlight class="keywordtype">double</highlight><highlight class="normal">)g;</highlight></codeline>
<codeline lineno="306"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="307"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="308"><highlight class="normal"></highlight></codeline>
<codeline lineno="309"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>norm<sp/>=<sp/>sqrtf((</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">)sum_sq);</highlight></codeline>
<codeline lineno="310"><highlight class="normal"></highlight></codeline>
<codeline lineno="311"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(norm<sp/>&gt;<sp/>max_norm)<sp/>{</highlight></codeline>
<codeline lineno="312"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>scale<sp/>=<sp/>max_norm<sp/>/<sp/>norm;</highlight></codeline>
<codeline lineno="313"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><ref refid="optimizer__kernels__bf16_8c_1a6a19ebe41c76f7394ecdc70784f0d449" kindref="member">gradient_scale_bf16</ref>(grad,<sp/>numel,<sp/>scale);</highlight></codeline>
<codeline lineno="314"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="315"><highlight class="normal"></highlight></codeline>
<codeline lineno="316"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>norm;</highlight></codeline>
<codeline lineno="317"><highlight class="normal">}</highlight></codeline>
    </programlisting>
    <location file="/home/antshiv/Workspace/C-Kernel-Engine/src/kernels/optimizer_kernels_bf16.c"/>
  </compounddef>
</doxygen>
