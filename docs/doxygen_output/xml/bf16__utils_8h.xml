<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.1" xml:lang="en-US">
  <compounddef id="bf16__utils_8h" kind="file" language="C++">
    <compoundname>bf16_utils.h</compoundname>
    <includes local="no">stdint.h</includes>
    <includes local="no">stddef.h</includes>
    <includedby refid="attention__kernels_8c" local="yes">attention_kernels.c</includedby>
    <includedby refid="embedding__kernels__bf16_8c" local="yes">embedding_kernels_bf16.c</includedby>
    <includedby refid="gelu__kernels__bf16_8c" local="yes">gelu_kernels_bf16.c</includedby>
    <includedby refid="gemm__kernels__bf16_8c" local="yes">gemm_kernels_bf16.c</includedby>
    <includedby refid="layernorm__kernels__bf16_8c" local="yes">layernorm_kernels_bf16.c</includedby>
    <includedby refid="loss__kernels__bf16_8c" local="yes">loss_kernels_bf16.c</includedby>
    <includedby refid="mlp__kernels__bf16_8c" local="yes">mlp_kernels_bf16.c</includedby>
    <includedby refid="relu__kernels__bf16_8c" local="yes">relu_kernels_bf16.c</includedby>
    <includedby refid="rmsnorm__kernels__bf16_8c" local="yes">rmsnorm_kernels_bf16.c</includedby>
    <includedby refid="rope__kernels__bf16_8c" local="yes">rope_kernels_bf16.c</includedby>
    <includedby refid="sigmoid__kernels__bf16_8c" local="yes">sigmoid_kernels_bf16.c</includedby>
    <includedby refid="softmax__kernels__bf16_8c" local="yes">softmax_kernels_bf16.c</includedby>
    <includedby refid="swiglu__kernels__bf16_8c" local="yes">swiglu_kernels_bf16.c</includedby>
    <includedby refid="vision__kernels__bf16_8c" local="yes">vision_kernels_bf16.c</includedby>
    <incdepgraph>
      <node id="2">
        <label>stdint.h</label>
      </node>
      <node id="1">
        <label>bf16_utils.h</label>
        <link refid="bf16__utils_8h"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
      </node>
      <node id="3">
        <label>stddef.h</label>
      </node>
    </incdepgraph>
    <invincdepgraph>
      <node id="11">
        <label>rope_kernels_bf16.c</label>
        <link refid="rope__kernels__bf16_8c"/>
      </node>
      <node id="9">
        <label>relu_kernels_bf16.c</label>
        <link refid="relu__kernels__bf16_8c"/>
      </node>
      <node id="12">
        <label>sigmoid_kernels_bf16.c</label>
        <link refid="sigmoid__kernels__bf16_8c"/>
      </node>
      <node id="7">
        <label>loss_kernels_bf16.c</label>
        <link refid="loss__kernels__bf16_8c"/>
      </node>
      <node id="1">
        <label>bf16_utils.h</label>
        <link refid="bf16__utils_8h"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
        <childnode refid="6" relation="include">
        </childnode>
        <childnode refid="7" relation="include">
        </childnode>
        <childnode refid="8" relation="include">
        </childnode>
        <childnode refid="9" relation="include">
        </childnode>
        <childnode refid="10" relation="include">
        </childnode>
        <childnode refid="11" relation="include">
        </childnode>
        <childnode refid="12" relation="include">
        </childnode>
        <childnode refid="13" relation="include">
        </childnode>
        <childnode refid="14" relation="include">
        </childnode>
        <childnode refid="15" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>attention_kernels.c</label>
        <link refid="attention__kernels_8c"/>
      </node>
      <node id="5">
        <label>gemm_kernels_bf16.c</label>
        <link refid="gemm__kernels__bf16_8c"/>
      </node>
      <node id="14">
        <label>swiglu_kernels_bf16.c</label>
        <link refid="swiglu__kernels__bf16_8c"/>
      </node>
      <node id="6">
        <label>layernorm_kernels_bf16.c</label>
        <link refid="layernorm__kernels__bf16_8c"/>
      </node>
      <node id="3">
        <label>embedding_kernels_bf16.c</label>
        <link refid="embedding__kernels__bf16_8c"/>
      </node>
      <node id="8">
        <label>mlp_kernels_bf16.c</label>
        <link refid="mlp__kernels__bf16_8c"/>
      </node>
      <node id="13">
        <label>softmax_kernels_bf16.c</label>
        <link refid="softmax__kernels__bf16_8c"/>
      </node>
      <node id="4">
        <label>gelu_kernels_bf16.c</label>
        <link refid="gelu__kernels__bf16_8c"/>
      </node>
      <node id="10">
        <label>rmsnorm_kernels_bf16.c</label>
        <link refid="rmsnorm__kernels__bf16_8c"/>
      </node>
      <node id="15">
        <label>vision_kernels_bf16.c</label>
        <link refid="vision__kernels__bf16_8c"/>
      </node>
    </invincdepgraph>
      <sectiondef kind="func">
      <memberdef kind="function" id="bf16__utils_8h_1a94c0b1e3b43eb46dcce37900ed5c1333" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void bf16_tensor_to_float</definition>
        <argsstring>(const uint16_t *src, float *dst, size_t count)</argsstring>
        <name>bf16_tensor_to_float</name>
        <param>
          <type>const uint16_t *</type>
          <declname>src</declname>
        </param>
        <param>
          <type>float *</type>
          <declname>dst</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>count</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" line="211" column="20" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" bodystart="211" bodyend="227"/>
        <references refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" compoundref="bf16__utils_8h" startline="38" endline="46">bf16_to_float</references>
        <referencedby refid="ckernel__engine_8h_1afe83b7a562f3b21fef1993782ff3792b" compoundref="softmax__kernels__bf16_8c" startline="36" endline="64">backward_causal_softmax_head_major_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a1cc637a888846ddbcf1a58ac72b4aaf6" compoundref="softmax__kernels__bf16_8c" startline="12" endline="34">causal_softmax_head_major_bf16</referencedby>
        <referencedby refid="attention__kernels_8c_1a4113194a0a57126146cb4d5471c05bd5" compoundref="attention__kernels_8c" startline="10" endline="19">convert_bf16_tensor</referencedby>
        <referencedby refid="ckernel__engine_8h_1ac8572265a21098caf2060797cb18a978" compoundref="gelu__kernels__bf16_8c" startline="37" endline="64">gelu_backward_exact_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a27adb4761d436aeea3317ce0595dc67a" compoundref="gelu__kernels__bf16_8c" startline="66" endline="91">gelu_backward_fast_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1aa64dae6724ac5d649be339cad62126cb" compoundref="gelu__kernels__bf16_8c" startline="21" endline="35">gelu_fast_inplace_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1ab4fae76462b8dfdda429b265c41ec9f0" compoundref="layernorm__kernels__bf16_8c" startline="83" endline="116">layernorm_backward_kernel_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1aed96ddab9e3b51974364c6a5dd5852a6" compoundref="layernorm__kernels__bf16_8c" startline="22" endline="51">layernorm_forward_rolled_slice_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a4b36f606ec3110c6da3844b3633b1aaf" compoundref="layernorm__kernels__bf16_8c" startline="53" endline="81">layernorm_forward_unrolled_slice_bf16</referencedby>
        <referencedby refid="mlp__kernels__bf16_8c_1ad863c8765e72bbaf7d00c2ec7a577fd4" compoundref="mlp__kernels__bf16_8c" startline="198" endline="269">mlp_token_parallel_bf16_fp32act</referencedby>
        <referencedby refid="ckernel__engine_8h_1ad3c7e02c4d88c86823c845ccbf72be6c" compoundref="rope__kernels__bf16_8c" startline="44" endline="70">rope_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a241f0f417dcac38a99613c909e6f3a5d" compoundref="rope__kernels__bf16_8c" startline="21" endline="42">rope_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a9d34029d73d757f5283f9adcfa219705" compoundref="sigmoid__kernels__bf16_8c" startline="37" endline="64">sigmoid_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a2e1b89ec838297259bbde96bc2bee0c6" compoundref="sigmoid__kernels__bf16_8c" startline="13" endline="35">sigmoid_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a5e87177162b6dd565515e53e56dcd0f5" compoundref="loss__kernels__bf16_8c" startline="8" endline="40">softmax_cross_entropy_loss_bf16</referencedby>
      </memberdef>
      <memberdef kind="function" id="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>float</type>
        <definition>static float bf16_to_float</definition>
        <argsstring>(uint16_t v)</argsstring>
        <name>bf16_to_float</name>
        <param>
          <type>uint16_t</type>
          <declname>v</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" line="38" column="21" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" bodystart="38" bodyend="46"/>
        <referencedby refid="gemm__kernels__bf16_8c_1a36f229bbda63818246ec86181b1fdd42" compoundref="gemm__kernels__bf16_8c" startline="41" endline="59">__attribute__</referencedby>
        <referencedby refid="bf16__utils_8h_1a94c0b1e3b43eb46dcce37900ed5c1333" compoundref="bf16__utils_8h" startline="211" endline="227">bf16_tensor_to_float</referencedby>
        <referencedby refid="ckernel__engine_8h_1a7c57b105fb88eb4165a0c649932be08d" compoundref="embedding__kernels__bf16_8c" startline="58" endline="99">embedding_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a6d58689c662e670a5423eedd0291d6b5" compoundref="embedding__kernels__bf16_8c" startline="7" endline="56">embedding_forward_bf16</referencedby>
        <referencedby refid="gemm__kernels__bf16_8c_1a8647bb8c6a9a965a92e1c98330f237af" compoundref="gemm__kernels__bf16_8c" startline="291" endline="343">gemm_bf16_fp32out</referencedby>
        <referencedby refid="gemm__kernels__bf16_8c_1ab1ff051870eb81a06b9d60bcda0c9399" compoundref="gemm__kernels__bf16_8c" startline="350" endline="414">gemm_nn_bf16</referencedby>
        <referencedby refid="gemm__kernels__bf16_8c_1a2184db7c1d029252c677e9bc0c71d80d" compoundref="gemm__kernels__bf16_8c" startline="417" endline="489">gemm_tn_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a488697bbc4656ba8037ab3eb79314e5e" compoundref="mlp__kernels__bf16_8c" startline="85" endline="191">mlp_token_parallel_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1aee95c2d2b45191471be617739a41ac0d" compoundref="vision__kernels__bf16_8c" startline="43" endline="81">patch2im_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1af64829ad63a9c81784d64d4f447ee39a" compoundref="relu__kernels__bf16_8c" startline="29" endline="42">relu_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a842c2002210a04d9dc4d9bdabed4fcc2" compoundref="relu__kernels__bf16_8c" startline="7" endline="16">relu_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a55d24741c224580192c6104c2eb4525a" compoundref="relu__kernels__bf16_8c" startline="18" endline="27">relu_forward_inplace_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a14d80153de303766038a231e4932e357" compoundref="rmsnorm__kernels__bf16_8c" startline="97" endline="222">rmsnorm_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a4f024774420774821f805d0742694d02" compoundref="rmsnorm__kernels__bf16_8c" startline="8" endline="94">rmsnorm_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a77fb89fc5fa2dcc73d9d37ccf9c50322" compoundref="swiglu__kernels__bf16_8c" startline="92" endline="152">swiglu_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a41a1dfc5976b7c2e2539a2811dc0b07f" compoundref="swiglu__kernels__bf16_8c" startline="50" endline="90">swiglu_forward_bf16</referencedby>
      </memberdef>
      <memberdef kind="function" id="bf16__utils_8h_1a027b5c4dd4c6ce7f656e922fc694e52a" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>void</type>
        <definition>static void float_tensor_to_bf16</definition>
        <argsstring>(const float *src, uint16_t *dst, size_t count)</argsstring>
        <name>float_tensor_to_bf16</name>
        <param>
          <type>const float *</type>
          <declname>src</declname>
        </param>
        <param>
          <type>uint16_t *</type>
          <declname>dst</declname>
        </param>
        <param>
          <type>size_t</type>
          <declname>count</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" line="232" column="20" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" bodystart="232" bodyend="248"/>
        <references refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" compoundref="bf16__utils_8h" startline="90" endline="103">float_to_bf16</references>
        <referencedby refid="ckernel__engine_8h_1afe83b7a562f3b21fef1993782ff3792b" compoundref="softmax__kernels__bf16_8c" startline="36" endline="64">backward_causal_softmax_head_major_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a1cc637a888846ddbcf1a58ac72b4aaf6" compoundref="softmax__kernels__bf16_8c" startline="12" endline="34">causal_softmax_head_major_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1ac8572265a21098caf2060797cb18a978" compoundref="gelu__kernels__bf16_8c" startline="37" endline="64">gelu_backward_exact_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a27adb4761d436aeea3317ce0595dc67a" compoundref="gelu__kernels__bf16_8c" startline="66" endline="91">gelu_backward_fast_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1aa64dae6724ac5d649be339cad62126cb" compoundref="gelu__kernels__bf16_8c" startline="21" endline="35">gelu_fast_inplace_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1ab4fae76462b8dfdda429b265c41ec9f0" compoundref="layernorm__kernels__bf16_8c" startline="83" endline="116">layernorm_backward_kernel_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1aed96ddab9e3b51974364c6a5dd5852a6" compoundref="layernorm__kernels__bf16_8c" startline="22" endline="51">layernorm_forward_rolled_slice_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a4b36f606ec3110c6da3844b3633b1aaf" compoundref="layernorm__kernels__bf16_8c" startline="53" endline="81">layernorm_forward_unrolled_slice_bf16</referencedby>
        <referencedby refid="mlp__kernels__bf16_8c_1ad863c8765e72bbaf7d00c2ec7a577fd4" compoundref="mlp__kernels__bf16_8c" startline="198" endline="269">mlp_token_parallel_bf16_fp32act</referencedby>
        <referencedby refid="ckernel__engine_8h_1ad3c7e02c4d88c86823c845ccbf72be6c" compoundref="rope__kernels__bf16_8c" startline="44" endline="70">rope_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a241f0f417dcac38a99613c909e6f3a5d" compoundref="rope__kernels__bf16_8c" startline="21" endline="42">rope_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a9d34029d73d757f5283f9adcfa219705" compoundref="sigmoid__kernels__bf16_8c" startline="37" endline="64">sigmoid_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a2e1b89ec838297259bbde96bc2bee0c6" compoundref="sigmoid__kernels__bf16_8c" startline="13" endline="35">sigmoid_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a5e87177162b6dd565515e53e56dcd0f5" compoundref="loss__kernels__bf16_8c" startline="8" endline="40">softmax_cross_entropy_loss_bf16</referencedby>
      </memberdef>
      <memberdef kind="function" id="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" prot="public" static="yes" const="no" explicit="no" inline="yes" virt="non-virtual">
        <type>uint16_t</type>
        <definition>static uint16_t float_to_bf16</definition>
        <argsstring>(float f)</argsstring>
        <name>float_to_bf16</name>
        <param>
          <type>float</type>
          <declname>f</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" line="90" column="24" bodyfile="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h" bodystart="90" bodyend="103"/>
        <referencedby refid="gemm__kernels__bf16_8c_1a36f229bbda63818246ec86181b1fdd42" compoundref="gemm__kernels__bf16_8c" startline="41" endline="59">__attribute__</referencedby>
        <referencedby refid="ckernel__engine_8h_1a7c57b105fb88eb4165a0c649932be08d" compoundref="embedding__kernels__bf16_8c" startline="58" endline="99">embedding_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a6d58689c662e670a5423eedd0291d6b5" compoundref="embedding__kernels__bf16_8c" startline="7" endline="56">embedding_forward_bf16</referencedby>
        <referencedby refid="bf16__utils_8h_1a027b5c4dd4c6ce7f656e922fc694e52a" compoundref="bf16__utils_8h" startline="232" endline="248">float_tensor_to_bf16</referencedby>
        <referencedby refid="gemm__kernels__bf16_8c_1ab1ff051870eb81a06b9d60bcda0c9399" compoundref="gemm__kernels__bf16_8c" startline="350" endline="414">gemm_nn_bf16</referencedby>
        <referencedby refid="gemm__kernels__bf16_8c_1a2184db7c1d029252c677e9bc0c71d80d" compoundref="gemm__kernels__bf16_8c" startline="417" endline="489">gemm_tn_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a488697bbc4656ba8037ab3eb79314e5e" compoundref="mlp__kernels__bf16_8c" startline="85" endline="191">mlp_token_parallel_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1aee95c2d2b45191471be617739a41ac0d" compoundref="vision__kernels__bf16_8c" startline="43" endline="81">patch2im_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1af64829ad63a9c81784d64d4f447ee39a" compoundref="relu__kernels__bf16_8c" startline="29" endline="42">relu_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a842c2002210a04d9dc4d9bdabed4fcc2" compoundref="relu__kernels__bf16_8c" startline="7" endline="16">relu_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a55d24741c224580192c6104c2eb4525a" compoundref="relu__kernels__bf16_8c" startline="18" endline="27">relu_forward_inplace_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a14d80153de303766038a231e4932e357" compoundref="rmsnorm__kernels__bf16_8c" startline="97" endline="222">rmsnorm_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a4f024774420774821f805d0742694d02" compoundref="rmsnorm__kernels__bf16_8c" startline="8" endline="94">rmsnorm_forward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a77fb89fc5fa2dcc73d9d37ccf9c50322" compoundref="swiglu__kernels__bf16_8c" startline="92" endline="152">swiglu_backward_bf16</referencedby>
        <referencedby refid="ckernel__engine_8h_1a41a1dfc5976b7c2e2539a2811dc0b07f" compoundref="swiglu__kernels__bf16_8c" startline="50" endline="90">swiglu_forward_bf16</referencedby>
      </memberdef>
      </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="preprocessor">#ifndef<sp/>BF16_UTILS_H</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="preprocessor">#define<sp/>BF16_UTILS_H</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stdint.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;stddef.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;immintrin.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight><highlight class="comment">//<sp/>BF16<sp/>(Brain<sp/>Floating<sp/>Point)<sp/>Format<sp/>Overview</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight><highlight class="comment">//<sp/>BF16<sp/>is<sp/>a<sp/>16-bit<sp/>floating-point<sp/>format<sp/>designed<sp/>for<sp/>machine<sp/>learning:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="16"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>FP32<sp/>(32<sp/>bits):<sp/><sp/>[S][EEEEEEEE][MMMMMMMMMMMMMMMMMMMMMMM]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="18"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>1<sp/><sp/><sp/><sp/>8<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>23<sp/>mantissa<sp/>bits</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="19"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="20"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>BF16<sp/>(16<sp/>bits):<sp/><sp/>[S][EEEEEEEE][MMMMMMM]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>1<sp/><sp/><sp/><sp/>8<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>7<sp/>mantissa<sp/>bits</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="23"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Key<sp/>insight:<sp/>BF16<sp/>is<sp/>the<sp/>UPPER<sp/>16<sp/>bits<sp/>of<sp/>FP32.<sp/>Same<sp/>exponent<sp/>range<sp/>(-126<sp/>to</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight><highlight class="comment">//<sp/>+127),<sp/>but<sp/>only<sp/>7<sp/>mantissa<sp/>bits<sp/>instead<sp/>of<sp/>23.<sp/>This<sp/>preserves<sp/>the<sp/>full</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="25"><highlight class="normal"></highlight><highlight class="comment">//<sp/>dynamic<sp/>range<sp/>of<sp/>FP32<sp/>while<sp/>sacrificing<sp/>precision.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="26"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="27"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Why<sp/>BF16<sp/>over<sp/>FP16?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="28"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>FP16<sp/>has<sp/>only<sp/>5<sp/>exponent<sp/>bits<sp/>(range<sp/>±65504),<sp/>causing<sp/>overflow<sp/>in<sp/>ML</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="29"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>BF16<sp/>has<sp/>8<sp/>exponent<sp/>bits<sp/>(same<sp/>as<sp/>FP32),<sp/>no<sp/>overflow<sp/>issues</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="30"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Conversion<sp/>is<sp/>trivial:<sp/>just<sp/>truncate/round<sp/>the<sp/>lower<sp/>16<sp/>bits</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="31"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="32"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="33"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Scalar<sp/>BF16<sp/>&lt;-&gt;<sp/>FP32<sp/>conversion</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="34"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="35"><highlight class="normal"></highlight></codeline>
<codeline lineno="36"><highlight class="normal"></highlight><highlight class="comment">//<sp/>BF16<sp/>to<sp/>FP32:<sp/>Zero-extend<sp/>the<sp/>16-bit<sp/>value<sp/>to<sp/>the<sp/>upper<sp/>half<sp/>of<sp/>FP32</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="37"><highlight class="normal"></highlight><highlight class="comment">//<sp/>This<sp/>is<sp/>lossless<sp/>-<sp/>every<sp/>BF16<sp/>value<sp/>maps<sp/>to<sp/>exactly<sp/>one<sp/>FP32<sp/>value.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="38" refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(uint16_t<sp/>v)</highlight></codeline>
<codeline lineno="39"><highlight class="normal">{</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">union<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="41"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uint32_t<sp/>u;</highlight></codeline>
<codeline lineno="42"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>f;</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/>tmp;</highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/><sp/><sp/>tmp.u<sp/>=<sp/>(uint32_t)v<sp/>&lt;&lt;<sp/>16;<sp/><sp/></highlight><highlight class="comment">//<sp/>Place<sp/>BF16<sp/>in<sp/>upper<sp/>16<sp/>bits,<sp/>lower<sp/>bits<sp/>=<sp/>0</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>tmp.f;</highlight></codeline>
<codeline lineno="46"><highlight class="normal">}</highlight></codeline>
<codeline lineno="47"><highlight class="normal"></highlight></codeline>
<codeline lineno="48"><highlight class="normal"></highlight><highlight class="comment">//<sp/>FP32<sp/>to<sp/>BF16:<sp/>Extract<sp/>upper<sp/>16<sp/>bits<sp/>with<sp/>ROUND-TO-NEAREST-EVEN<sp/>rounding</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="49"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="50"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Why<sp/>not<sp/>just<sp/>truncate<sp/>(&gt;&gt;<sp/>16)?</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="51"><highlight class="normal"></highlight><highlight class="comment">//<sp/>─────────────────────────────</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="52"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Simple<sp/>truncation<sp/>always<sp/>rounds<sp/>DOWN,<sp/>creating<sp/>systematic<sp/>negative<sp/>bias.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="53"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Over<sp/>many<sp/>operations,<sp/>this<sp/>compounds:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>1.999...<sp/>truncates<sp/>to<sp/>1.0<sp/>(lost<sp/>0.999)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="55"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>2.001...<sp/>truncates<sp/>to<sp/>2.0<sp/>(lost<sp/>0.001)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="56"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Average<sp/>error:<sp/>-0.5<sp/>LSB<sp/>(always<sp/>negative!)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="57"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="58"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Round-to-nearest-even<sp/>algorithm:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="59"><highlight class="normal"></highlight><highlight class="comment">//<sp/>────────────────────────────────</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="60"><highlight class="normal"></highlight><highlight class="comment">//<sp/>We<sp/>add<sp/>a<sp/>rounding<sp/>bias<sp/>before<sp/>truncating.<sp/>The<sp/>bias<sp/>depends<sp/>on<sp/>the<sp/>LSB</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="61"><highlight class="normal"></highlight><highlight class="comment">//<sp/>(least<sp/>significant<sp/>bit)<sp/>of<sp/>the<sp/>result<sp/>to<sp/>implement<sp/>&quot;banker&apos;s<sp/>rounding&quot;:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="62"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="63"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Fractional<sp/>part<sp/>&lt;<sp/>0.5:<sp/><sp/>Round<sp/>down<sp/>(add<sp/>0x7FFF,<sp/>doesn&apos;t<sp/>overflow<sp/>to<sp/>next)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="64"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Fractional<sp/>part<sp/>&gt;<sp/>0.5:<sp/><sp/>Round<sp/>up<sp/><sp/><sp/>(add<sp/>0x7FFF,<sp/>overflows<sp/>to<sp/>next)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="65"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Fractional<sp/>part<sp/>=<sp/>0.5:<sp/><sp/>Round<sp/>to<sp/>EVEN<sp/>(add<sp/>0x7FFF<sp/>+<sp/>LSB)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="66"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>If<sp/>result<sp/>LSB=0<sp/>(even),<sp/>add<sp/>0x7FFF<sp/>→<sp/>stays<sp/>same</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="67"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>If<sp/>result<sp/>LSB=1<sp/>(odd),<sp/><sp/>add<sp/>0x8000<sp/>→<sp/>rounds<sp/>up</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="68"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="69"><highlight class="normal"></highlight><highlight class="comment">//<sp/>The<sp/>magic<sp/>constant<sp/>0x7FFF<sp/>is<sp/>&quot;almost<sp/>half&quot;<sp/>of<sp/>the<sp/>lower<sp/>16<sp/>bits<sp/>(0xFFFF).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="70"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Adding<sp/>0x7FFF<sp/>+<sp/>lsb<sp/>effectively<sp/>rounds<sp/>to<sp/>nearest,<sp/>with<sp/>ties<sp/>going<sp/>to<sp/>even.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="71"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="72"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Example:<sp/>Converting<sp/>FP32<sp/>1.5f<sp/>(exactly<sp/>representable<sp/>in<sp/>BF16)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="73"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>FP32<sp/>bits:<sp/>0x3FC00000<sp/>=<sp/>0011<sp/>1111<sp/>1100<sp/>0000<sp/>|<sp/>0000<sp/>0000<sp/>0000<sp/>0000</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="74"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>^^^^^^^^^^^^^^^^^^<sp/><sp/><sp/>^^^^^^^^^^^^^^^^^^</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="75"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>upper<sp/>16<sp/>(BF16)<sp/><sp/><sp/><sp/><sp/><sp/>lower<sp/>16<sp/>(to<sp/>discard)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="76"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Lower<sp/>16<sp/>=<sp/>0x0000,<sp/>LSB<sp/>of<sp/>upper<sp/>=<sp/>0</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="77"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Add<sp/>0x7FFF<sp/>+<sp/>0<sp/>=<sp/>0x7FFF:<sp/>0x3FC07FFF</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="78"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Shift<sp/>&gt;&gt;<sp/>16:<sp/>0x3FC0<sp/>✓<sp/>(no<sp/>change,<sp/>fraction<sp/>was<sp/>0)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="79"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="80"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Example:<sp/>Converting<sp/>FP32<sp/>1.0000001f<sp/>(not<sp/>exact<sp/>in<sp/>BF16)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="81"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>FP32<sp/>bits:<sp/>0x3F800001</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="82"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Lower<sp/>16<sp/>=<sp/>0x0001,<sp/>LSB<sp/>of<sp/>upper<sp/>=<sp/>0</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="83"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Add<sp/>0x7FFF:<sp/>0x3F808000<sp/>→<sp/>overflows<sp/>upper<sp/>bits</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="84"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Shift<sp/>&gt;&gt;<sp/>16:<sp/>0x3F80<sp/>(rounded<sp/>down,<sp/>fraction<sp/>&lt;<sp/>0.5)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="85"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="86"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Example:<sp/>Converting<sp/>FP32<sp/>1.0078125f<sp/>(BF16<sp/>boundary,<sp/>exactly<sp/>0.5<sp/>between)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="87"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>This<sp/>is<sp/>exactly<sp/>halfway<sp/>between<sp/>two<sp/>BF16<sp/>values</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="88"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Round-to-even<sp/>picks<sp/>the<sp/>one<sp/>with<sp/>LSB=0</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="89"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="90" refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/>uint16_t<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>f)</highlight></codeline>
<codeline lineno="91"><highlight class="normal">{</highlight></codeline>
<codeline lineno="92"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">union<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uint32_t<sp/>u;</highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>f;</highlight></codeline>
<codeline lineno="95"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/>tmp;</highlight></codeline>
<codeline lineno="96"><highlight class="normal"><sp/><sp/><sp/><sp/>tmp.f<sp/>=<sp/>f;</highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Extract<sp/>bit<sp/>16<sp/>(will<sp/>be<sp/>the<sp/>LSB<sp/>of<sp/>the<sp/>BF16<sp/>result<sp/>after<sp/>truncation)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="98"><highlight class="normal"><sp/><sp/><sp/><sp/>uint32_t<sp/>lsb<sp/>=<sp/>(tmp.u<sp/>&gt;&gt;<sp/>16)<sp/>&amp;<sp/>1u;</highlight></codeline>
<codeline lineno="99"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Add<sp/>rounding<sp/>bias:<sp/>0x7FFF<sp/>normally,<sp/>0x8000<sp/>if<sp/>LSB=1<sp/>(rounds<sp/>ties<sp/>to<sp/>even)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="100"><highlight class="normal"><sp/><sp/><sp/><sp/>tmp.u<sp/>+=<sp/>0x7FFFu<sp/>+<sp/>lsb;</highlight></codeline>
<codeline lineno="101"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Truncate<sp/>lower<sp/>16<sp/>bits</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>(uint16_t)(tmp.u<sp/>&gt;&gt;<sp/>16);</highlight></codeline>
<codeline lineno="103"><highlight class="normal">}</highlight></codeline>
<codeline lineno="104"><highlight class="normal"></highlight></codeline>
<codeline lineno="105"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="106"><highlight class="normal"></highlight><highlight class="comment">//<sp/>AVX-512<sp/>BF16<sp/>&lt;-&gt;<sp/>FP32<sp/>conversion<sp/>(16<sp/>elements<sp/>at<sp/>a<sp/>time)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="107"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="108"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="109"><highlight class="normal"></highlight><highlight class="comment">//<sp/>AVX-512<sp/>provides<sp/>512-bit<sp/>registers<sp/>(16<sp/>floats)<sp/>for<sp/>efficient<sp/>vectorization.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="110"><highlight class="normal"></highlight><highlight class="comment">//<sp/>We<sp/>process<sp/>16<sp/>BF16<sp/>values<sp/>at<sp/>once,<sp/>stored<sp/>in<sp/>a<sp/>256-bit<sp/>register<sp/>(__m256i).</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="112"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Memory<sp/>layout<sp/>for<sp/>16<sp/>BF16<sp/>values<sp/>(32<sp/>bytes):</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="113"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>__m256i:<sp/>[bf16_0][bf16_1][bf16_2]...[bf16_15]<sp/><sp/>(16<sp/>×<sp/>16-bit)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="114"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="115"><highlight class="normal"></highlight><highlight class="comment">//<sp/>After<sp/>conversion<sp/>to<sp/>FP32<sp/>(64<sp/>bytes):</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="116"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>__m512:<sp/><sp/>[fp32_0][fp32_1][fp32_2]...[fp32_15]<sp/><sp/>(16<sp/>×<sp/>32-bit)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="117"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="118"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="119"><highlight class="normal"></highlight></codeline>
<codeline lineno="120"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="121"><highlight class="normal"></highlight></codeline>
<codeline lineno="122"><highlight class="normal"></highlight><highlight class="comment">//<sp/>BF16<sp/>to<sp/>FP32<sp/>vectorized:<sp/>Zero-extend<sp/>16-bit<sp/>→<sp/>32-bit,<sp/>then<sp/>shift<sp/>left<sp/>16</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="123"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="124"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Step-by-step<sp/>for<sp/>one<sp/>element<sp/>(but<sp/>done<sp/>for<sp/>all<sp/>16<sp/>in<sp/>parallel):</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="125"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Input<sp/>BF16:<sp/><sp/><sp/>0x3F80<sp/>(represents<sp/>1.0f)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="126"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Zero-extend:<sp/><sp/>0x00003F80</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="127"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>Shift<sp/>&lt;&lt;<sp/>16:<sp/><sp/>0x3F800000<sp/>(IEEE-754<sp/>for<sp/>1.0f)<sp/>✓</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="128"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="129"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/>__m512<sp/>bf16x16_to_fp32(__m256i<sp/>bf16_vec)</highlight></codeline>
<codeline lineno="130"><highlight class="normal">{</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Zero-extend<sp/>16<sp/>×<sp/>uint16<sp/>to<sp/>16<sp/>×<sp/>uint32</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512i<sp/>as_int<sp/>=<sp/>_mm512_cvtepu16_epi32(bf16_vec);</highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Shift<sp/>each<sp/>32-bit<sp/>value<sp/>left<sp/>by<sp/>16<sp/>bits<sp/>(move<sp/>BF16<sp/>to<sp/>upper<sp/>half)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512i<sp/>shifted<sp/>=<sp/>_mm512_slli_epi32(as_int,<sp/>16);</highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Reinterpret<sp/>bits<sp/>as<sp/>float<sp/>(no<sp/>conversion,<sp/>just<sp/>type<sp/>cast)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>_mm512_castsi512_ps(shifted);</highlight></codeline>
<codeline lineno="137"><highlight class="normal">}</highlight></codeline>
<codeline lineno="138"><highlight class="normal"></highlight></codeline>
<codeline lineno="139"><highlight class="normal"></highlight><highlight class="comment">//<sp/>FP32<sp/>to<sp/>BF16<sp/>vectorized:<sp/>Same<sp/>round-to-nearest-even<sp/>algorithm,<sp/>SIMD<sp/>version</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="140"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="141"><highlight class="normal"></highlight><highlight class="comment">//<sp/>This<sp/>is<sp/>the<sp/>vectorized<sp/>equivalent<sp/>of<sp/>float_to_bf16()<sp/>above.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="142"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Each<sp/>of<sp/>the<sp/>16<sp/>lanes<sp/>independently<sp/>performs:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="143"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>1.<sp/>Extract<sp/>LSB<sp/>of<sp/>would-be<sp/>BF16<sp/>result</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="144"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>2.<sp/>Add<sp/>rounding<sp/>bias<sp/>(0x7FFF<sp/>+<sp/>lsb)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="145"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>3.<sp/>Truncate<sp/>by<sp/>right-shifting<sp/>16<sp/>bits</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="147"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/>__m256i<sp/>fp32x16_to_bf16(__m512<sp/>fp32_vec)</highlight></codeline>
<codeline lineno="148"><highlight class="normal">{</highlight></codeline>
<codeline lineno="149"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Reinterpret<sp/>float<sp/>bits<sp/>as<sp/>integers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512i<sp/>as_int<sp/>=<sp/>_mm512_castps_si512(fp32_vec);</highlight></codeline>
<codeline lineno="151"><highlight class="normal"></highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Extract<sp/>bit<sp/>16<sp/>of<sp/>each<sp/>value<sp/>(this<sp/>becomes<sp/>LSB<sp/>of<sp/>BF16<sp/>result)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512i<sp/>lsb<sp/>=<sp/>_mm512_srli_epi32(as_int,<sp/>16);</highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/><sp/><sp/>lsb<sp/>=<sp/>_mm512_and_si512(lsb,<sp/>_mm512_set1_epi32(1));</highlight></codeline>
<codeline lineno="155"><highlight class="normal"></highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Compute<sp/>rounding<sp/>bias:<sp/>0x7FFF<sp/>+<sp/>lsb<sp/>(0x7FFF<sp/>or<sp/>0x8000)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512i<sp/>rounding<sp/>=<sp/>_mm512_add_epi32(_mm512_set1_epi32(0x7FFF),<sp/>lsb);</highlight></codeline>
<codeline lineno="158"><highlight class="normal"></highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Add<sp/>rounding<sp/>bias<sp/>and<sp/>shift<sp/>right<sp/>to<sp/>get<sp/>BF16<sp/>value</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512i<sp/>rounded<sp/>=<sp/>_mm512_add_epi32(as_int,<sp/>rounding);</highlight></codeline>
<codeline lineno="161"><highlight class="normal"><sp/><sp/><sp/><sp/>__m512i<sp/>shifted<sp/>=<sp/>_mm512_srli_epi32(rounded,<sp/>16);</highlight></codeline>
<codeline lineno="162"><highlight class="normal"></highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Pack<sp/>16<sp/>×<sp/>32-bit<sp/>down<sp/>to<sp/>16<sp/>×<sp/>16-bit<sp/>(truncates<sp/>upper<sp/>bits,<sp/>which<sp/>are<sp/>0)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>_mm512_cvtepi32_epi16(shifted);</highlight></codeline>
<codeline lineno="165"><highlight class="normal">}</highlight></codeline>
<codeline lineno="166"><highlight class="normal"></highlight></codeline>
<codeline lineno="167"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convenience:<sp/>Load<sp/>16<sp/>BF16<sp/>values<sp/>from<sp/>memory<sp/>and<sp/>convert<sp/>to<sp/>FP32</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="168"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/>__m512<sp/>bf16_loadu_cvt_fp32(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*ptr)</highlight></codeline>
<codeline lineno="169"><highlight class="normal">{</highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/>__m256i<sp/>bf16_vec<sp/>=<sp/>_mm256_loadu_si256((</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>__m256i<sp/>*)ptr);</highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>bf16x16_to_fp32(bf16_vec);</highlight></codeline>
<codeline lineno="172"><highlight class="normal">}</highlight></codeline>
<codeline lineno="173"><highlight class="normal"></highlight></codeline>
<codeline lineno="174"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convenience:<sp/>Convert<sp/>16<sp/>FP32<sp/>values<sp/>to<sp/>BF16<sp/>and<sp/>store<sp/>to<sp/>memory</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="175"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>fp32_cvt_storeu_bf16(uint16_t<sp/>*ptr,<sp/>__m512<sp/>fp32_vec)</highlight></codeline>
<codeline lineno="176"><highlight class="normal">{</highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/><sp/><sp/>__m256i<sp/>bf16_vec<sp/>=<sp/>fp32x16_to_bf16(fp32_vec);</highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/><sp/><sp/>_mm256_storeu_si256((__m256i<sp/>*)ptr,<sp/>bf16_vec);</highlight></codeline>
<codeline lineno="179"><highlight class="normal">}</highlight></codeline>
<codeline lineno="180"><highlight class="normal"></highlight></codeline>
<codeline lineno="181"><highlight class="normal"></highlight><highlight class="preprocessor">#endif<sp/></highlight><highlight class="comment">/*<sp/>__AVX512F__<sp/>*/</highlight><highlight class="preprocessor"></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="182"><highlight class="normal"></highlight></codeline>
<codeline lineno="183"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="184"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Tensor<sp/>conversion<sp/>functions<sp/>(use<sp/>SIMD<sp/>when<sp/>available)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="185"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="186"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="187"><highlight class="normal"></highlight><highlight class="comment">//<sp/>These<sp/>functions<sp/>convert<sp/>entire<sp/>tensors<sp/>between<sp/>BF16<sp/>and<sp/>FP32.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="188"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Two<sp/>common<sp/>usage<sp/>patterns<sp/>in<sp/>neural<sp/>network<sp/>inference:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="189"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="190"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Pattern<sp/>1:<sp/>Convert-Compute-Convert</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="191"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Load<sp/>BF16<sp/>weights/activations</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="192"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Convert<sp/>entire<sp/>tensor<sp/>to<sp/>FP32</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="193"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Compute<sp/>in<sp/>FP32<sp/>for<sp/>full<sp/>precision</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="194"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Convert<sp/>result<sp/>back<sp/>to<sp/>BF16</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="195"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Good<sp/>for:<sp/>Simple<sp/>ops,<sp/>debugging,<sp/>when<sp/>memory<sp/>isn&apos;t<sp/>critical</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="196"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="197"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Pattern<sp/>2:<sp/>Inline<sp/>Conversion<sp/>(preferred<sp/>for<sp/>performance)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="198"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Load<sp/>BF16<sp/>values<sp/>directly<sp/>in<sp/>compute<sp/>kernel</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="199"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Convert<sp/>to<sp/>FP32<sp/>in<sp/>registers<sp/>(no<sp/>memory<sp/>write)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="200"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Compute<sp/>in<sp/>FP32</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="201"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Convert<sp/>back<sp/>to<sp/>BF16<sp/>before<sp/>storing</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="202"><highlight class="normal"></highlight><highlight class="comment">//<sp/><sp/><sp/>-<sp/>Good<sp/>for:<sp/>GEMM,<sp/>activations,<sp/>fused<sp/>kernels</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="203"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="204"><highlight class="normal"></highlight><highlight class="comment">//<sp/>The<sp/>functions<sp/>below<sp/>implement<sp/>Pattern<sp/>1.<sp/>For<sp/>Pattern<sp/>2,<sp/>use</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="205"><highlight class="normal"></highlight><highlight class="comment">//<sp/>bf16_loadu_cvt_fp32()<sp/>and<sp/>fp32_cvt_storeu_bf16()<sp/>directly<sp/>in<sp/>kernels.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="206"><highlight class="normal"></highlight><highlight class="comment">//</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="207"><highlight class="normal"></highlight><highlight class="comment">//<sp/>============================================================================</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="208"><highlight class="normal"></highlight></codeline>
<codeline lineno="209"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convert<sp/>BF16<sp/>tensor<sp/>to<sp/>FP32<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="210"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Uses<sp/>AVX-512<sp/>when<sp/>available<sp/>(16<sp/>elements<sp/>per<sp/>iteration)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="211" refid="bf16__utils_8h_1a94c0b1e3b43eb46dcce37900ed5c1333" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="bf16__utils_8h_1a94c0b1e3b43eb46dcce37900ed5c1333" kindref="member">bf16_tensor_to_float</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>uint16_t<sp/>*src,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*dst,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>count)</highlight></codeline>
<codeline lineno="212"><highlight class="normal">{</highlight></codeline>
<codeline lineno="213"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="214"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="215"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>+<sp/>16<sp/>&lt;=<sp/>count;<sp/>i<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="216"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>fp32_vec<sp/>=<sp/>bf16_loadu_cvt_fp32(&amp;src[i]);</highlight></codeline>
<codeline lineno="217"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>_mm512_storeu_ps(&amp;dst[i],<sp/>fp32_vec);</highlight></codeline>
<codeline lineno="218"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="219"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>&lt;<sp/>count;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="220"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dst[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(src[i]);</highlight></codeline>
<codeline lineno="221"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="222"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="223"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>count;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="224"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dst[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a314c3970fd5e2770d19b1bb49aefcf94" kindref="member">bf16_to_float</ref>(src[i]);</highlight></codeline>
<codeline lineno="225"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="226"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="227"><highlight class="normal">}</highlight></codeline>
<codeline lineno="228"><highlight class="normal"></highlight></codeline>
<codeline lineno="229"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Convert<sp/>FP32<sp/>tensor<sp/>to<sp/>BF16<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="230"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Uses<sp/>AVX-512<sp/>when<sp/>available<sp/>(16<sp/>elements<sp/>per<sp/>iteration)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="231"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Applies<sp/>round-to-nearest-even<sp/>for<sp/>each<sp/>conversion</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="232" refid="bf16__utils_8h_1a027b5c4dd4c6ce7f656e922fc694e52a" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">static</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">inline</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="bf16__utils_8h_1a027b5c4dd4c6ce7f656e922fc694e52a" kindref="member">float_tensor_to_bf16</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*src,<sp/>uint16_t<sp/>*dst,<sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>count)</highlight></codeline>
<codeline lineno="233"><highlight class="normal">{</highlight></codeline>
<codeline lineno="234"><highlight class="normal"></highlight><highlight class="preprocessor">#if<sp/>defined(__AVX512F__)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;</highlight></codeline>
<codeline lineno="236"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>+<sp/>16<sp/>&lt;=<sp/>count;<sp/>i<sp/>+=<sp/>16)<sp/>{</highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>__m512<sp/>fp32_vec<sp/>=<sp/>_mm512_loadu_ps(&amp;src[i]);</highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>fp32_cvt_storeu_bf16(&amp;dst[i],<sp/>fp32_vec);</highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(;<sp/>i<sp/>&lt;<sp/>count;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="241"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dst[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(src[i]);</highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="243"><highlight class="normal"></highlight><highlight class="preprocessor">#else</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="244"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>count;<sp/>++i)<sp/>{</highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dst[i]<sp/>=<sp/><ref refid="bf16__utils_8h_1a174b16a92b3a5972230d7519fc0c5aa3" kindref="member">float_to_bf16</ref>(src[i]);</highlight></codeline>
<codeline lineno="246"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="247"><highlight class="normal"></highlight><highlight class="preprocessor">#endif</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="248"><highlight class="normal">}</highlight></codeline>
<codeline lineno="249"><highlight class="normal"></highlight></codeline>
<codeline lineno="250"><highlight class="normal"></highlight><highlight class="preprocessor">#endif<sp/></highlight><highlight class="comment">/*<sp/>BF16_UTILS_H<sp/>*/</highlight><highlight class="preprocessor"></highlight></codeline>
    </programlisting>
    <location file="/home/antshiv/Workspace/C-Kernel-Engine/include/bf16_utils.h"/>
  </compounddef>
</doxygen>
